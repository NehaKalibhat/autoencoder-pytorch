Logging************pruning 97 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 778 / 1152  0.6753472222222222
encoder.0.bias : 77 / 128  0.6015625
encoder.2.weight : 130863 / 131072  0.9984054565429688
encoder.2.bias : 64 / 64  1.0
encoder.4.weight : 7735 / 8192  0.9442138671875
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4111 / 4608  0.8921440972222222
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1041 / 1152  0.9036458333333334
encoder.9.bias : 7 / 8  0.875
decoder.0.weight : 8444 / 9216  0.9162326388888888
decoder.0.bias : 106 / 128  0.828125
decoder.2.weight : 30968 / 32768  0.945068359375
decoder.2.bias : 26 / 64  0.40625
decoder.4.weight : 7226 / 8192  0.882080078125
decoder.4.bias : 15 / 32  0.46875
decoder.6.weight : 11882 / 12800  0.92828125
decoder.6.bias : 10 / 16  0.625
decoder.8.weight : 12 / 64  0.1875
decoder.8.bias : 1 / 1  1.0
Fraction of weights pruned = 203413/209705 = 0.9699959466870127
Number of parameters in model 209705
epoch [1/100], loss:0.2583
epoch [2/100], loss:0.2470
epoch [3/100], loss:0.2291
epoch [4/100], loss:0.2218
epoch [5/100], loss:0.2277
epoch [6/100], loss:0.2325
epoch [7/100], loss:0.2303
epoch [8/100], loss:0.2192
epoch [9/100], loss:0.2335
epoch [10/100], loss:0.2465
epoch [11/100], loss:0.2368
epoch [12/100], loss:0.2434
epoch [13/100], loss:0.2151
epoch [14/100], loss:0.2243
epoch [15/100], loss:0.2294
epoch [16/100], loss:0.2263
epoch [17/100], loss:0.2245
epoch [18/100], loss:0.2394
epoch [19/100], loss:0.2345
epoch [20/100], loss:0.2243
epoch [21/100], loss:0.2429
epoch [22/100], loss:0.2274
epoch [23/100], loss:0.2238
epoch [24/100], loss:0.2230
epoch [25/100], loss:0.2401
epoch [26/100], loss:0.2306
epoch [27/100], loss:0.2321
epoch [28/100], loss:0.2276
epoch [29/100], loss:0.2349
epoch [30/100], loss:0.2293
epoch [31/100], loss:0.2329
epoch [32/100], loss:0.2388
epoch [33/100], loss:0.2344
epoch [34/100], loss:0.2338
epoch [35/100], loss:0.2264
epoch [36/100], loss:0.2255
epoch [37/100], loss:0.2318
epoch [38/100], loss:0.2187
epoch [39/100], loss:0.2168
epoch [40/100], loss:0.2163
epoch [41/100], loss:0.2346
epoch [42/100], loss:0.2161
epoch [43/100], loss:0.2327
epoch [44/100], loss:0.2184
epoch [45/100], loss:0.2266
epoch [46/100], loss:0.2239
epoch [47/100], loss:0.2214
epoch [48/100], loss:0.2253
epoch [49/100], loss:0.2185
epoch [50/100], loss:0.2227
epoch [51/100], loss:0.2351
epoch [52/100], loss:0.2223
epoch [53/100], loss:0.2306
epoch [54/100], loss:0.2297
epoch [55/100], loss:0.2387
epoch [56/100], loss:0.2147
epoch [57/100], loss:0.2342
epoch [58/100], loss:0.2306
epoch [59/100], loss:0.2321
epoch [60/100], loss:0.2305
epoch [61/100], loss:0.2342
epoch [62/100], loss:0.2215
epoch [63/100], loss:0.2306
epoch [64/100], loss:0.2418
epoch [65/100], loss:0.2354
epoch [66/100], loss:0.2153
epoch [67/100], loss:0.2260
epoch [68/100], loss:0.2136
epoch [69/100], loss:0.2290
epoch [70/100], loss:0.2213
epoch [71/100], loss:0.2313
epoch [72/100], loss:0.2142
epoch [73/100], loss:0.2286
epoch [74/100], loss:0.2316
epoch [75/100], loss:0.2122
epoch [76/100], loss:0.2326
epoch [77/100], loss:0.2284
epoch [78/100], loss:0.2278
epoch [79/100], loss:0.2325
epoch [80/100], loss:0.2257
epoch [81/100], loss:0.2298
epoch [82/100], loss:0.2232
epoch [83/100], loss:0.2295
epoch [84/100], loss:0.2164
epoch [85/100], loss:0.2303
epoch [86/100], loss:0.2130
epoch [87/100], loss:0.2312
epoch [88/100], loss:0.2196
epoch [89/100], loss:0.2291
epoch [90/100], loss:0.2211
epoch [91/100], loss:0.2286
epoch [92/100], loss:0.2282
epoch [93/100], loss:0.2245
epoch [94/100], loss:0.2226
epoch [95/100], loss:0.2169
epoch [96/100], loss:0.2310
epoch [97/100], loss:0.2294
epoch [98/100], loss:0.2302
epoch [99/100], loss:0.2211
epoch [100/100], loss:0.2166
