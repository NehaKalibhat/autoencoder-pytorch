tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,
        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,
        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,
        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,
        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,
        2, 0, 2, 7, 1, 8, 6, 4])
[20.0, 16.0, 12.8, 10.240000000000002, 8.192, 6.5536, 5.2428799999999995, 4.194304, 3.3554431999999994, 2.68435456, 2.1474836479999992, 1.7179869183999985, 1.3743895347199981, 1.099511627775999, 0.8796093022207998, 0.7036874417766399, 0.5629499534213125, 0.45035996273705053, 0.3602879701896399, 0.28823037615171077, 0.23058430092136747]
Weight fractions: [20.0, 36.0, 48.8, 59.04, 67.232, 73.7856, 79.02848, 83.222784, 86.5782272, 89.26258176, 91.41006540800001, 93.12805232640001, 94.50244186112, 95.601953488896, 96.4815627911168, 97.18525023289344, 97.74820018631475, 98.1985601490518, 98.55884811924145, 98.84707849539316]
***************Iterative Pruning started. Number of iterations: 20 *****************
Running pruning iteration 0
************pruning 20.0 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 2 / 1152  0.001736111111111111
encoder.0.bias : 0 / 128  0.0
encoder.2.weight : 34348 / 131072  0.262054443359375
encoder.2.bias : 8 / 64  0.125
encoder.4.weight : 743 / 8192  0.0906982421875
encoder.4.bias : 0 / 32  0.0
encoder.6.weight : 159 / 4608  0.034505208333333336
encoder.6.bias : 1 / 16  0.0625
encoder.9.weight : 9 / 1152  0.0078125
encoder.9.bias : 0 / 8  0.0
decoder.0.weight : 840 / 9216  0.09114583333333333
decoder.0.bias : 0 / 128  0.0
decoder.2.weight : 3493 / 32768  0.106597900390625
decoder.2.bias : 0 / 64  0.0
decoder.4.weight : 962 / 8192  0.117431640625
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 1372 / 12800  0.1071875
decoder.6.bias : 0 / 16  0.0
decoder.8.weight : 4 / 64  0.0625
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 41941/209705 = 0.2
Number of parameters in model 209705
epoch [1/100], loss:0.4006
epoch [2/100], loss:0.3926
epoch [3/100], loss:0.3832
epoch [4/100], loss:0.3928
epoch [5/100], loss:0.4027
epoch [6/100], loss:0.0979
epoch [7/100], loss:0.0759
epoch [8/100], loss:0.0632
epoch [9/100], loss:0.0623
epoch [10/100], loss:0.0547
epoch [11/100], loss:0.0511
epoch [12/100], loss:0.0552
epoch [13/100], loss:0.0489
epoch [14/100], loss:0.0445
epoch [15/100], loss:0.0435
epoch [16/100], loss:0.0389
epoch [17/100], loss:0.0444
epoch [18/100], loss:0.0433
epoch [19/100], loss:0.0390
epoch [20/100], loss:0.0384
epoch [21/100], loss:0.0394
epoch [22/100], loss:0.0337
epoch [23/100], loss:0.0312
epoch [24/100], loss:0.0363
epoch [25/100], loss:0.0351
epoch [26/100], loss:0.0356
epoch [27/100], loss:0.0357
epoch [28/100], loss:0.0331
epoch [29/100], loss:0.0329
epoch [30/100], loss:0.0330
epoch [31/100], loss:0.0334
epoch [32/100], loss:0.0379
epoch [33/100], loss:0.0311
epoch [34/100], loss:0.0306
epoch [35/100], loss:0.0311
epoch [36/100], loss:0.0299
epoch [37/100], loss:0.0333
epoch [38/100], loss:0.0352
epoch [39/100], loss:0.0335
epoch [40/100], loss:0.0293
epoch [41/100], loss:0.0317
epoch [42/100], loss:0.0295
epoch [43/100], loss:0.0291
epoch [44/100], loss:0.0307
epoch [45/100], loss:0.0297
epoch [46/100], loss:0.0296
epoch [47/100], loss:0.0287
epoch [48/100], loss:0.0278
epoch [49/100], loss:0.0283
epoch [50/100], loss:0.0271
epoch [51/100], loss:0.0318
epoch [52/100], loss:0.0300
epoch [53/100], loss:0.0319
epoch [54/100], loss:0.0298
epoch [55/100], loss:0.0255
epoch [56/100], loss:0.0305
epoch [57/100], loss:0.0274
epoch [58/100], loss:0.0255
epoch [59/100], loss:0.0280
epoch [60/100], loss:0.0289
epoch [61/100], loss:0.0268
epoch [62/100], loss:0.0269
epoch [63/100], loss:0.0240
epoch [64/100], loss:0.0267
epoch [65/100], loss:0.0269
epoch [66/100], loss:0.0312
epoch [67/100], loss:0.0272
epoch [68/100], loss:0.0309
epoch [69/100], loss:0.0291
epoch [70/100], loss:0.0334
epoch [71/100], loss:0.0281
epoch [72/100], loss:0.0255
epoch [73/100], loss:0.0277
epoch [74/100], loss:0.0274
epoch [75/100], loss:0.0262
epoch [76/100], loss:0.0298
epoch [77/100], loss:0.0275
epoch [78/100], loss:0.0245
epoch [79/100], loss:0.0270
epoch [80/100], loss:0.0243
epoch [81/100], loss:0.0273
epoch [82/100], loss:0.0255
epoch [83/100], loss:0.0279
epoch [84/100], loss:0.0251
epoch [85/100], loss:0.0280
epoch [86/100], loss:0.0250
epoch [87/100], loss:0.0257
epoch [88/100], loss:0.0271
epoch [89/100], loss:0.0224
epoch [90/100], loss:0.0284
epoch [91/100], loss:0.0242
epoch [92/100], loss:0.0288
epoch [93/100], loss:0.0249
epoch [94/100], loss:0.0274
epoch [95/100], loss:0.0262
epoch [96/100], loss:0.0289
epoch [97/100], loss:0.0237
epoch [98/100], loss:0.0256
epoch [99/100], loss:0.0270
epoch [100/100], loss:0.0220
Running pruning iteration 1
************pruning 36.0 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 18 / 1152  0.015625
encoder.0.bias : 0 / 128  0.0
encoder.2.weight : 60533 / 131072  0.46183013916015625
encoder.2.bias : 12 / 64  0.1875
encoder.4.weight : 1964 / 8192  0.23974609375
encoder.4.bias : 0 / 32  0.0
encoder.6.weight : 391 / 4608  0.08485243055555555
encoder.6.bias : 1 / 16  0.0625
encoder.9.weight : 86 / 1152  0.07465277777777778
encoder.9.bias : 0 / 8  0.0
decoder.0.weight : 1650 / 9216  0.17903645833333334
decoder.0.bias : 0 / 128  0.0
decoder.2.weight : 6624 / 32768  0.2021484375
decoder.2.bias : 0 / 64  0.0
decoder.4.weight : 1739 / 8192  0.2122802734375
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 2469 / 12800  0.192890625
decoder.6.bias : 0 / 16  0.0
decoder.8.weight : 7 / 64  0.109375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 75494/209705 = 0.3600009537207029
Number of parameters in model 209705
epoch [1/100], loss:0.4147
epoch [2/100], loss:0.4112
epoch [3/100], loss:0.3987
epoch [4/100], loss:0.1395
epoch [5/100], loss:0.0679
epoch [6/100], loss:0.0533
epoch [7/100], loss:0.0558
epoch [8/100], loss:0.0484
epoch [9/100], loss:0.0417
epoch [10/100], loss:0.0372
epoch [11/100], loss:0.0381
epoch [12/100], loss:0.0368
epoch [13/100], loss:0.0358
epoch [14/100], loss:0.0309
epoch [15/100], loss:0.0348
epoch [16/100], loss:0.0326
epoch [17/100], loss:0.0273
epoch [18/100], loss:0.0287
epoch [19/100], loss:0.0310
epoch [20/100], loss:0.0311
epoch [21/100], loss:0.0250
epoch [22/100], loss:0.0267
epoch [23/100], loss:0.0290
epoch [24/100], loss:0.0277
epoch [25/100], loss:0.0308
epoch [26/100], loss:0.0259
epoch [27/100], loss:0.0278
epoch [28/100], loss:0.0291
epoch [29/100], loss:0.0215
epoch [30/100], loss:0.0242
epoch [31/100], loss:0.0261
epoch [32/100], loss:0.0247
epoch [33/100], loss:0.0244
epoch [34/100], loss:0.0243
epoch [35/100], loss:0.0226
epoch [36/100], loss:0.0249
epoch [37/100], loss:0.0225
epoch [38/100], loss:0.0234
epoch [39/100], loss:0.0196
epoch [40/100], loss:0.0211
epoch [41/100], loss:0.0255
epoch [42/100], loss:0.0218
epoch [43/100], loss:0.0197
epoch [44/100], loss:0.0225
epoch [45/100], loss:0.0226
epoch [46/100], loss:0.0230
epoch [47/100], loss:0.0237
epoch [48/100], loss:0.0203
epoch [49/100], loss:0.0204
epoch [50/100], loss:0.0200
epoch [51/100], loss:0.0209
epoch [52/100], loss:0.0180
epoch [53/100], loss:0.0203
epoch [54/100], loss:0.0207
epoch [55/100], loss:0.0170
epoch [56/100], loss:0.0232
epoch [57/100], loss:0.0196
epoch [58/100], loss:0.0194
epoch [59/100], loss:0.0204
epoch [60/100], loss:0.0190
epoch [61/100], loss:0.0166
epoch [62/100], loss:0.0191
epoch [63/100], loss:0.0178
epoch [64/100], loss:0.0204
epoch [65/100], loss:0.0184
epoch [66/100], loss:0.0177
epoch [67/100], loss:0.0209
epoch [68/100], loss:0.0159
epoch [69/100], loss:0.0173
epoch [70/100], loss:0.0177
epoch [71/100], loss:0.0169
epoch [72/100], loss:0.0176
epoch [73/100], loss:0.0194
epoch [74/100], loss:0.0189
epoch [75/100], loss:0.0185
epoch [76/100], loss:0.0175
epoch [77/100], loss:0.0167
epoch [78/100], loss:0.0199
epoch [79/100], loss:0.0179
epoch [80/100], loss:0.0175
epoch [81/100], loss:0.0164
epoch [82/100], loss:0.0181
epoch [83/100], loss:0.0199
epoch [84/100], loss:0.0176
epoch [85/100], loss:0.0175
epoch [86/100], loss:0.0192
epoch [87/100], loss:0.0167
epoch [88/100], loss:0.0161
epoch [89/100], loss:0.0177
epoch [90/100], loss:0.0178
epoch [91/100], loss:0.0198
epoch [92/100], loss:0.0169
epoch [93/100], loss:0.0174
epoch [94/100], loss:0.0170
epoch [95/100], loss:0.0186
epoch [96/100], loss:0.0163
epoch [97/100], loss:0.0183
epoch [98/100], loss:0.0167
epoch [99/100], loss:0.0155
epoch [100/100], loss:0.0177
Running pruning iteration 2
************pruning 48.8 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 27 / 1152  0.0234375
encoder.0.bias : 0 / 128  0.0
encoder.2.weight : 80626 / 131072  0.6151275634765625
encoder.2.bias : 23 / 64  0.359375
encoder.4.weight : 2749 / 8192  0.3355712890625
encoder.4.bias : 0 / 32  0.0
encoder.6.weight : 723 / 4608  0.15690104166666666
encoder.6.bias : 2 / 16  0.125
encoder.9.weight : 155 / 1152  0.1345486111111111
encoder.9.bias : 0 / 8  0.0
decoder.0.weight : 2771 / 9216  0.3006727430555556
decoder.0.bias : 3 / 128  0.0234375
decoder.2.weight : 9389 / 32768  0.286529541015625
decoder.2.bias : 0 / 64  0.0
decoder.4.weight : 2292 / 8192  0.27978515625
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 3566 / 12800  0.27859375
decoder.6.bias : 0 / 16  0.0
decoder.8.weight : 10 / 64  0.15625
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 102336/209705 = 0.4879998092558594
Number of parameters in model 209705
epoch [1/100], loss:0.1087
epoch [2/100], loss:0.0903
epoch [3/100], loss:0.0683
epoch [4/100], loss:0.0674
epoch [5/100], loss:0.0657
epoch [6/100], loss:0.0609
epoch [7/100], loss:0.0547
epoch [8/100], loss:0.0590
epoch [9/100], loss:0.0551
epoch [10/100], loss:0.0561
epoch [11/100], loss:0.0534
epoch [12/100], loss:0.0459
epoch [13/100], loss:0.0506
epoch [14/100], loss:0.0496
epoch [15/100], loss:0.0474
epoch [16/100], loss:0.0457
epoch [17/100], loss:0.0412
epoch [18/100], loss:0.0443
epoch [19/100], loss:0.0534
epoch [20/100], loss:0.0423
epoch [21/100], loss:0.0461
epoch [22/100], loss:0.0414
epoch [23/100], loss:0.0433
epoch [24/100], loss:0.0440
epoch [25/100], loss:0.0473
epoch [26/100], loss:0.0430
epoch [27/100], loss:0.0467
epoch [28/100], loss:0.0476
epoch [29/100], loss:0.0421
epoch [30/100], loss:0.0440
epoch [31/100], loss:0.0446
epoch [32/100], loss:0.0398
epoch [33/100], loss:0.0410
epoch [34/100], loss:0.0409
epoch [35/100], loss:0.0373
epoch [36/100], loss:0.0413
epoch [37/100], loss:0.0446
epoch [38/100], loss:0.0366
epoch [39/100], loss:0.0390
epoch [40/100], loss:0.0346
epoch [41/100], loss:0.0367
epoch [42/100], loss:0.0370
epoch [43/100], loss:0.0433
epoch [44/100], loss:0.0379
epoch [45/100], loss:0.0380
epoch [46/100], loss:0.0363
epoch [47/100], loss:0.0372
epoch [48/100], loss:0.0394
epoch [49/100], loss:0.0366
epoch [50/100], loss:0.0368
epoch [51/100], loss:0.0341
epoch [52/100], loss:0.0359
epoch [53/100], loss:0.0417
epoch [54/100], loss:0.0423
epoch [55/100], loss:0.0314
epoch [56/100], loss:0.0316
epoch [57/100], loss:0.0326
epoch [58/100], loss:0.0322
epoch [59/100], loss:0.0299
epoch [60/100], loss:0.0363
epoch [61/100], loss:0.0326
epoch [62/100], loss:0.0334
epoch [63/100], loss:0.0290
epoch [64/100], loss:0.0324
epoch [65/100], loss:0.0324
epoch [66/100], loss:0.0291
epoch [67/100], loss:0.0303
epoch [68/100], loss:0.0318
epoch [69/100], loss:0.0302
epoch [70/100], loss:0.0313
epoch [71/100], loss:0.0301
epoch [72/100], loss:0.0271
epoch [73/100], loss:0.0319
epoch [74/100], loss:0.0311
epoch [75/100], loss:0.0273
epoch [76/100], loss:0.0314
epoch [77/100], loss:0.0308
epoch [78/100], loss:0.0328
epoch [79/100], loss:0.0319
epoch [80/100], loss:0.0284
epoch [81/100], loss:0.0290
epoch [82/100], loss:0.0264
epoch [83/100], loss:0.0272
epoch [84/100], loss:0.0288
epoch [85/100], loss:0.0299
epoch [86/100], loss:0.0302
epoch [87/100], loss:0.0294
epoch [88/100], loss:0.0295
epoch [89/100], loss:0.0291
epoch [90/100], loss:0.0252
epoch [91/100], loss:0.0259
epoch [92/100], loss:0.0322
epoch [93/100], loss:0.0245
epoch [94/100], loss:0.0288
epoch [95/100], loss:0.0281
epoch [96/100], loss:0.0307
epoch [97/100], loss:0.0314
epoch [98/100], loss:0.0303
epoch [99/100], loss:0.0312
epoch [100/100], loss:0.0288
Running pruning iteration 3
************pruning 59.04 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 158 / 1152  0.1371527777777778
encoder.0.bias : 12 / 128  0.09375
encoder.2.weight : 92069 / 131072  0.7024307250976562
encoder.2.bias : 30 / 64  0.46875
encoder.4.weight : 3867 / 8192  0.4720458984375
encoder.4.bias : 10 / 32  0.3125
encoder.6.weight : 1152 / 4608  0.25
encoder.6.bias : 3 / 16  0.1875
encoder.9.weight : 449 / 1152  0.3897569444444444
encoder.9.bias : 2 / 8  0.25
decoder.0.weight : 4925 / 9216  0.5343967013888888
decoder.0.bias : 3 / 128  0.0234375
decoder.2.weight : 12167 / 32768  0.371307373046875
decoder.2.bias : 0 / 64  0.0
decoder.4.weight : 2507 / 8192  0.3060302734375
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 6426 / 12800  0.50203125
decoder.6.bias : 4 / 16  0.25
decoder.8.weight : 26 / 64  0.40625
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 123810/209705 = 0.5904008011253904
Number of parameters in model 209705
epoch [1/100], loss:0.0992
epoch [2/100], loss:0.0834
epoch [3/100], loss:0.0770
epoch [4/100], loss:0.0651
epoch [5/100], loss:0.0637
epoch [6/100], loss:0.0610
epoch [7/100], loss:0.0566
epoch [8/100], loss:0.0526
epoch [9/100], loss:0.0490
epoch [10/100], loss:0.0499
epoch [11/100], loss:0.0485
epoch [12/100], loss:0.0487
epoch [13/100], loss:0.0487
epoch [14/100], loss:0.0497
epoch [15/100], loss:0.0526
epoch [16/100], loss:0.0454
epoch [17/100], loss:0.0420
epoch [18/100], loss:0.0432
epoch [19/100], loss:0.0409
epoch [20/100], loss:0.0395
epoch [21/100], loss:0.0418
epoch [22/100], loss:0.0348
epoch [23/100], loss:0.0372
epoch [24/100], loss:0.0374
epoch [25/100], loss:0.0347
epoch [26/100], loss:0.0430
epoch [27/100], loss:0.0364
epoch [28/100], loss:0.0346
epoch [29/100], loss:0.0334
epoch [30/100], loss:0.0385
epoch [31/100], loss:0.0392
epoch [32/100], loss:0.0392
epoch [33/100], loss:0.0374
epoch [34/100], loss:0.0386
epoch [35/100], loss:0.0377
epoch [36/100], loss:0.0378
epoch [37/100], loss:0.0377
epoch [38/100], loss:0.0394
epoch [39/100], loss:0.0378
epoch [40/100], loss:0.0345
epoch [41/100], loss:0.0363
epoch [42/100], loss:0.0316
epoch [43/100], loss:0.0376
epoch [44/100], loss:0.0355
epoch [45/100], loss:0.0311
epoch [46/100], loss:0.0376
epoch [47/100], loss:0.0301
epoch [48/100], loss:0.0341
epoch [49/100], loss:0.0301
epoch [50/100], loss:0.0328
epoch [51/100], loss:0.0324
epoch [52/100], loss:0.0296
epoch [53/100], loss:0.0345
epoch [54/100], loss:0.0320
epoch [55/100], loss:0.0311
epoch [56/100], loss:0.0298
epoch [57/100], loss:0.0330
epoch [58/100], loss:0.0305
epoch [59/100], loss:0.0293
epoch [60/100], loss:0.0345
epoch [61/100], loss:0.0306
epoch [62/100], loss:0.0299
epoch [63/100], loss:0.0312
epoch [64/100], loss:0.0347
epoch [65/100], loss:0.0356
epoch [66/100], loss:0.0320
epoch [67/100], loss:0.0335
epoch [68/100], loss:0.0308
epoch [69/100], loss:0.0354
epoch [70/100], loss:0.0333
epoch [71/100], loss:0.0330
epoch [72/100], loss:0.0320
epoch [73/100], loss:0.0314
epoch [74/100], loss:0.0368
epoch [75/100], loss:0.0296
epoch [76/100], loss:0.0328
epoch [77/100], loss:0.0329
epoch [78/100], loss:0.0304
epoch [79/100], loss:0.0335
epoch [80/100], loss:0.0278
epoch [81/100], loss:0.0293
epoch [82/100], loss:0.0301
epoch [83/100], loss:0.0315
epoch [84/100], loss:0.0286
epoch [85/100], loss:0.0282
epoch [86/100], loss:0.0295
epoch [87/100], loss:0.0305
epoch [88/100], loss:0.0281
epoch [89/100], loss:0.0311
epoch [90/100], loss:0.0259
epoch [91/100], loss:0.0288
epoch [92/100], loss:0.0313
epoch [93/100], loss:0.0276
epoch [94/100], loss:0.0308
epoch [95/100], loss:0.0277
epoch [96/100], loss:0.0285
epoch [97/100], loss:0.0272
epoch [98/100], loss:0.0318
epoch [99/100], loss:0.0295
epoch [100/100], loss:0.0278
Running pruning iteration 4
************pruning 67.232 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 292 / 1152  0.2534722222222222
encoder.0.bias : 30 / 128  0.234375
encoder.2.weight : 102665 / 131072  0.7832717895507812
encoder.2.bias : 35 / 64  0.546875
encoder.4.weight : 4980 / 8192  0.60791015625
encoder.4.bias : 16 / 32  0.5
encoder.6.weight : 1892 / 4608  0.4105902777777778
encoder.6.bias : 4 / 16  0.25
encoder.9.weight : 730 / 1152  0.6336805555555556
encoder.9.bias : 4 / 8  0.5
decoder.0.weight : 6660 / 9216  0.72265625
decoder.0.bias : 8 / 128  0.0625
decoder.2.weight : 13726 / 32768  0.41888427734375
decoder.2.bias : 1 / 64  0.015625
decoder.4.weight : 2833 / 8192  0.3458251953125
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 7079 / 12800  0.553046875
decoder.6.bias : 5 / 16  0.3125
decoder.8.weight : 29 / 64  0.453125
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 140989/209705 = 0.6723206409003123
Number of parameters in model 209705
epoch [1/100], loss:0.1364
epoch [2/100], loss:0.0928
epoch [3/100], loss:0.0869
epoch [4/100], loss:0.0723
epoch [5/100], loss:0.0723
epoch [6/100], loss:0.0761
epoch [7/100], loss:0.0703
epoch [8/100], loss:0.0609
epoch [9/100], loss:0.0600
epoch [10/100], loss:0.0583
epoch [11/100], loss:0.0632
epoch [12/100], loss:0.0508
epoch [13/100], loss:0.0655
epoch [14/100], loss:0.0506
epoch [15/100], loss:0.0579
epoch [16/100], loss:0.0557
epoch [17/100], loss:0.0510
epoch [18/100], loss:0.0463
epoch [19/100], loss:0.0473
epoch [20/100], loss:0.0514
epoch [21/100], loss:0.0469
epoch [22/100], loss:0.0455
epoch [23/100], loss:0.0459
epoch [24/100], loss:0.0474
epoch [25/100], loss:0.0463
epoch [26/100], loss:0.0410
epoch [27/100], loss:0.0416
epoch [28/100], loss:0.0444
epoch [29/100], loss:0.0437
epoch [30/100], loss:0.0423
epoch [31/100], loss:0.0423
epoch [32/100], loss:0.0449
epoch [33/100], loss:0.0393
epoch [34/100], loss:0.0458
epoch [35/100], loss:0.0429
epoch [36/100], loss:0.0449
epoch [37/100], loss:0.0375
epoch [38/100], loss:0.0380
epoch [39/100], loss:0.0375
epoch [40/100], loss:0.0429
epoch [41/100], loss:0.0376
epoch [42/100], loss:0.0390
epoch [43/100], loss:0.0400
epoch [44/100], loss:0.0355
epoch [45/100], loss:0.0363
epoch [46/100], loss:0.0359
epoch [47/100], loss:0.0401
epoch [48/100], loss:0.0412
epoch [49/100], loss:0.0328
epoch [50/100], loss:0.0369
epoch [51/100], loss:0.0380
epoch [52/100], loss:0.0387
epoch [53/100], loss:0.0331
epoch [54/100], loss:0.0329
epoch [55/100], loss:0.0311
epoch [56/100], loss:0.0363
epoch [57/100], loss:0.0348
epoch [58/100], loss:0.0392
epoch [59/100], loss:0.0367
epoch [60/100], loss:0.0359
epoch [61/100], loss:0.0352
epoch [62/100], loss:0.0323
epoch [63/100], loss:0.0340
epoch [64/100], loss:0.0360
epoch [65/100], loss:0.0313
epoch [66/100], loss:0.0371
epoch [67/100], loss:0.0316
epoch [68/100], loss:0.0294
epoch [69/100], loss:0.0296
epoch [70/100], loss:0.0356
epoch [71/100], loss:0.0283
epoch [72/100], loss:0.0298
epoch [73/100], loss:0.0312
epoch [74/100], loss:0.0282
epoch [75/100], loss:0.0281
epoch [76/100], loss:0.0332
epoch [77/100], loss:0.0314
epoch [78/100], loss:0.0388
epoch [79/100], loss:0.0294
epoch [80/100], loss:0.0281
epoch [81/100], loss:0.0343
epoch [82/100], loss:0.0327
epoch [83/100], loss:0.0338
epoch [84/100], loss:0.0307
epoch [85/100], loss:0.0286
epoch [86/100], loss:0.0328
epoch [87/100], loss:0.0325
epoch [88/100], loss:0.0291
epoch [89/100], loss:0.0297
epoch [90/100], loss:0.0274
epoch [91/100], loss:0.0302
epoch [92/100], loss:0.0292
epoch [93/100], loss:0.0295
epoch [94/100], loss:0.0332
epoch [95/100], loss:0.0266
epoch [96/100], loss:0.0311
epoch [97/100], loss:0.0316
epoch [98/100], loss:0.0308
epoch [99/100], loss:0.0299
epoch [100/100], loss:0.0312
Running pruning iteration 5
************pruning 73.7856 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 347 / 1152  0.3012152777777778
encoder.0.bias : 40 / 128  0.3125
encoder.2.weight : 110231 / 131072  0.8409957885742188
encoder.2.bias : 42 / 64  0.65625
encoder.4.weight : 5966 / 8192  0.728271484375
encoder.4.bias : 19 / 32  0.59375
encoder.6.weight : 2174 / 4608  0.4717881944444444
encoder.6.bias : 4 / 16  0.25
encoder.9.weight : 740 / 1152  0.6423611111111112
encoder.9.bias : 4 / 8  0.5
decoder.0.weight : 6972 / 9216  0.7565104166666666
decoder.0.bias : 12 / 128  0.09375
decoder.2.weight : 15083 / 32768  0.460296630859375
decoder.2.bias : 1 / 64  0.015625
decoder.4.weight : 3269 / 8192  0.3990478515625
decoder.4.bias : 0 / 32  0.0
decoder.6.weight : 9781 / 12800  0.764140625
decoder.6.bias : 9 / 16  0.5625
decoder.8.weight : 38 / 64  0.59375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 154732/209705 = 0.737855558999547
Number of parameters in model 209705
epoch [1/100], loss:0.1406
epoch [2/100], loss:0.1260
epoch [3/100], loss:0.0993
epoch [4/100], loss:0.1023
epoch [5/100], loss:0.0894
epoch [6/100], loss:0.0854
epoch [7/100], loss:0.0792
epoch [8/100], loss:0.0786
epoch [9/100], loss:0.0767
epoch [10/100], loss:0.0747
epoch [11/100], loss:0.0743
epoch [12/100], loss:0.0602
epoch [13/100], loss:0.0694
epoch [14/100], loss:0.0548
epoch [15/100], loss:0.0651
epoch [16/100], loss:0.0565
epoch [17/100], loss:0.0670
epoch [18/100], loss:0.0617
epoch [19/100], loss:0.0626
epoch [20/100], loss:0.0555
epoch [21/100], loss:0.0634
epoch [22/100], loss:0.0576
epoch [23/100], loss:0.0578
epoch [24/100], loss:0.0537
epoch [25/100], loss:0.0595
epoch [26/100], loss:0.0519
epoch [27/100], loss:0.0527
epoch [28/100], loss:0.0485
epoch [29/100], loss:0.0518
epoch [30/100], loss:0.0528
epoch [31/100], loss:0.0500
epoch [32/100], loss:0.0526
epoch [33/100], loss:0.0474
epoch [34/100], loss:0.0493
epoch [35/100], loss:0.0452
epoch [36/100], loss:0.0508
epoch [37/100], loss:0.0538
epoch [38/100], loss:0.0488
epoch [39/100], loss:0.0477
epoch [40/100], loss:0.0489
epoch [41/100], loss:0.0504
epoch [42/100], loss:0.0458
epoch [43/100], loss:0.0548
epoch [44/100], loss:0.0477
epoch [45/100], loss:0.0476
epoch [46/100], loss:0.0415
epoch [47/100], loss:0.0491
epoch [48/100], loss:0.0457
epoch [49/100], loss:0.0424
epoch [50/100], loss:0.0376
epoch [51/100], loss:0.0468
epoch [52/100], loss:0.0466
epoch [53/100], loss:0.0452
epoch [54/100], loss:0.0434
epoch [55/100], loss:0.0455
epoch [56/100], loss:0.0478
epoch [57/100], loss:0.0495
epoch [58/100], loss:0.0410
epoch [59/100], loss:0.0467
epoch [60/100], loss:0.0381
epoch [61/100], loss:0.0459
epoch [62/100], loss:0.0475
epoch [63/100], loss:0.0450
epoch [64/100], loss:0.0425
epoch [65/100], loss:0.0411
epoch [66/100], loss:0.0427
epoch [67/100], loss:0.0425
epoch [68/100], loss:0.0426
epoch [69/100], loss:0.0440
epoch [70/100], loss:0.0429
epoch [71/100], loss:0.0541
epoch [72/100], loss:0.0427
epoch [73/100], loss:0.0428
epoch [74/100], loss:0.0430
epoch [75/100], loss:0.0409
epoch [76/100], loss:0.0449
epoch [77/100], loss:0.0440
epoch [78/100], loss:0.0418
epoch [79/100], loss:0.0417
epoch [80/100], loss:0.0446
epoch [81/100], loss:0.0368
epoch [82/100], loss:0.0373
epoch [83/100], loss:0.0369
epoch [84/100], loss:0.0426
epoch [85/100], loss:0.0415
epoch [86/100], loss:0.0413
epoch [87/100], loss:0.0373
epoch [88/100], loss:0.0422
epoch [89/100], loss:0.0420
epoch [90/100], loss:0.0437
epoch [91/100], loss:0.0470
epoch [92/100], loss:0.0384
epoch [93/100], loss:0.0376
epoch [94/100], loss:0.0382
epoch [95/100], loss:0.0400
epoch [96/100], loss:0.0389
epoch [97/100], loss:0.0408
epoch [98/100], loss:0.0373
epoch [99/100], loss:0.0376
epoch [100/100], loss:0.0395
Running pruning iteration 6
************pruning 79.02848 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 414 / 1152  0.359375
encoder.0.bias : 47 / 128  0.3671875
encoder.2.weight : 115116 / 131072  0.878265380859375
encoder.2.bias : 45 / 64  0.703125
encoder.4.weight : 6896 / 8192  0.841796875
encoder.4.bias : 28 / 32  0.875
encoder.6.weight : 2939 / 4608  0.6378038194444444
encoder.6.bias : 5 / 16  0.3125
encoder.9.weight : 776 / 1152  0.6736111111111112
encoder.9.bias : 4 / 8  0.5
decoder.0.weight : 7303 / 9216  0.7924262152777778
decoder.0.bias : 35 / 128  0.2734375
decoder.2.weight : 18029 / 32768  0.550201416015625
decoder.2.bias : 6 / 64  0.09375
decoder.4.weight : 3831 / 8192  0.4676513671875
decoder.4.bias : 1 / 32  0.03125
decoder.6.weight : 10195 / 12800  0.796484375
decoder.6.bias : 10 / 16  0.625
decoder.8.weight : 46 / 64  0.71875
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 165726/209705 = 0.790281586037529
Number of parameters in model 209705
epoch [1/100], loss:0.1618
epoch [2/100], loss:0.1260
epoch [3/100], loss:0.1164
epoch [4/100], loss:0.0927
epoch [5/100], loss:0.0737
epoch [6/100], loss:0.0829
epoch [7/100], loss:0.0757
epoch [8/100], loss:0.0695
epoch [9/100], loss:0.0710
epoch [10/100], loss:0.0742
epoch [11/100], loss:0.0702
epoch [12/100], loss:0.0651
epoch [13/100], loss:0.0659
epoch [14/100], loss:0.0539
epoch [15/100], loss:0.0617
epoch [16/100], loss:0.0647
epoch [17/100], loss:0.0592
epoch [18/100], loss:0.0651
epoch [19/100], loss:0.0596
epoch [20/100], loss:0.0602
epoch [21/100], loss:0.0554
epoch [22/100], loss:0.0608
epoch [23/100], loss:0.0585
epoch [24/100], loss:0.0554
epoch [25/100], loss:0.0545
epoch [26/100], loss:0.0560
epoch [27/100], loss:0.0619
epoch [28/100], loss:0.0590
epoch [29/100], loss:0.0597
epoch [30/100], loss:0.0615
epoch [31/100], loss:0.0586
epoch [32/100], loss:0.0514
epoch [33/100], loss:0.0525
epoch [34/100], loss:0.0543
epoch [35/100], loss:0.0540
epoch [36/100], loss:0.0486
epoch [37/100], loss:0.0539
epoch [38/100], loss:0.0519
epoch [39/100], loss:0.0484
epoch [40/100], loss:0.0536
epoch [41/100], loss:0.0504
epoch [42/100], loss:0.0474
epoch [43/100], loss:0.0485
epoch [44/100], loss:0.0480
epoch [45/100], loss:0.0508
epoch [46/100], loss:0.0528
epoch [47/100], loss:0.0519
epoch [48/100], loss:0.0484
epoch [49/100], loss:0.0481
epoch [50/100], loss:0.0519
epoch [51/100], loss:0.0482
epoch [52/100], loss:0.0497
epoch [53/100], loss:0.0484
epoch [54/100], loss:0.0445
epoch [55/100], loss:0.0473
epoch [56/100], loss:0.0564
epoch [57/100], loss:0.0438
epoch [58/100], loss:0.0459
epoch [59/100], loss:0.0452
epoch [60/100], loss:0.0487
epoch [61/100], loss:0.0400
epoch [62/100], loss:0.0487
epoch [63/100], loss:0.0463
epoch [64/100], loss:0.0452
epoch [65/100], loss:0.0430
epoch [66/100], loss:0.0448
epoch [67/100], loss:0.0462
epoch [68/100], loss:0.0502
epoch [69/100], loss:0.0473
epoch [70/100], loss:0.0504
epoch [71/100], loss:0.0421
epoch [72/100], loss:0.0445
epoch [73/100], loss:0.0434
epoch [74/100], loss:0.0428
epoch [75/100], loss:0.0414
epoch [76/100], loss:0.0465
epoch [77/100], loss:0.0427
epoch [78/100], loss:0.0436
epoch [79/100], loss:0.0405
epoch [80/100], loss:0.0401
epoch [81/100], loss:0.0372
epoch [82/100], loss:0.0467
epoch [83/100], loss:0.0465
epoch [84/100], loss:0.0409
epoch [85/100], loss:0.0439
epoch [86/100], loss:0.0451
epoch [87/100], loss:0.0447
epoch [88/100], loss:0.0397
epoch [89/100], loss:0.0391
epoch [90/100], loss:0.0394
epoch [91/100], loss:0.0416
epoch [92/100], loss:0.0404
epoch [93/100], loss:0.0452
epoch [94/100], loss:0.0456
epoch [95/100], loss:0.0461
epoch [96/100], loss:0.0439
epoch [97/100], loss:0.0418
epoch [98/100], loss:0.0403
epoch [99/100], loss:0.0387
epoch [100/100], loss:0.0419
Running pruning iteration 7
************pruning 83.222784 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 446 / 1152  0.3871527777777778
encoder.0.bias : 49 / 128  0.3828125
encoder.2.weight : 118052 / 131072  0.900665283203125
encoder.2.bias : 45 / 64  0.703125
encoder.4.weight : 6978 / 8192  0.851806640625
encoder.4.bias : 30 / 32  0.9375
encoder.6.weight : 3213 / 4608  0.697265625
encoder.6.bias : 8 / 16  0.5
encoder.9.weight : 830 / 1152  0.7204861111111112
encoder.9.bias : 4 / 8  0.5
decoder.0.weight : 7629 / 9216  0.8277994791666666
decoder.0.bias : 58 / 128  0.453125
decoder.2.weight : 21305 / 32768  0.650177001953125
decoder.2.bias : 9 / 64  0.140625
decoder.4.weight : 4250 / 8192  0.518798828125
decoder.4.bias : 2 / 32  0.0625
decoder.6.weight : 11547 / 12800  0.902109375
decoder.6.bias : 12 / 16  0.75
decoder.8.weight : 55 / 64  0.859375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 174522/209705 = 0.832226222550726
Number of parameters in model 209705
epoch [1/100], loss:0.1969
epoch [2/100], loss:0.1539
epoch [3/100], loss:0.1299
epoch [4/100], loss:0.1254
epoch [5/100], loss:0.1120
epoch [6/100], loss:0.1060
epoch [7/100], loss:0.0892
epoch [8/100], loss:0.0887
epoch [9/100], loss:0.0831
epoch [10/100], loss:0.0867
epoch [11/100], loss:0.0806
epoch [12/100], loss:0.0806
epoch [13/100], loss:0.0812
epoch [14/100], loss:0.0752
epoch [15/100], loss:0.0780
epoch [16/100], loss:0.0769
epoch [17/100], loss:0.0766
epoch [18/100], loss:0.0822
epoch [19/100], loss:0.0721
epoch [20/100], loss:0.0704
epoch [21/100], loss:0.0740
epoch [22/100], loss:0.0688
epoch [23/100], loss:0.0627
epoch [24/100], loss:0.0704
epoch [25/100], loss:0.0619
epoch [26/100], loss:0.0688
epoch [27/100], loss:0.0653
epoch [28/100], loss:0.0660
epoch [29/100], loss:0.0707
epoch [30/100], loss:0.0668
epoch [31/100], loss:0.0658
epoch [32/100], loss:0.0670
epoch [33/100], loss:0.0665
epoch [34/100], loss:0.0641
epoch [35/100], loss:0.0646
epoch [36/100], loss:0.0654
epoch [37/100], loss:0.0578
epoch [38/100], loss:0.0680
epoch [39/100], loss:0.0672
epoch [40/100], loss:0.0665
epoch [41/100], loss:0.0653
epoch [42/100], loss:0.0645
epoch [43/100], loss:0.0640
epoch [44/100], loss:0.0624
epoch [45/100], loss:0.0642
epoch [46/100], loss:0.0605
epoch [47/100], loss:0.0658
epoch [48/100], loss:0.0562
epoch [49/100], loss:0.0567
epoch [50/100], loss:0.0577
epoch [51/100], loss:0.0571
epoch [52/100], loss:0.0611
epoch [53/100], loss:0.0596
epoch [54/100], loss:0.0543
epoch [55/100], loss:0.0546
epoch [56/100], loss:0.0608
epoch [57/100], loss:0.0581
epoch [58/100], loss:0.0542
epoch [59/100], loss:0.0607
epoch [60/100], loss:0.0613
epoch [61/100], loss:0.0564
epoch [62/100], loss:0.0589
epoch [63/100], loss:0.0559
epoch [64/100], loss:0.0598
epoch [65/100], loss:0.0506
epoch [66/100], loss:0.0639
epoch [67/100], loss:0.0575
epoch [68/100], loss:0.0586
epoch [69/100], loss:0.0565
epoch [70/100], loss:0.0613
epoch [71/100], loss:0.0607
epoch [72/100], loss:0.0583
epoch [73/100], loss:0.0574
epoch [74/100], loss:0.0582
epoch [75/100], loss:0.0685
epoch [76/100], loss:0.0563
epoch [77/100], loss:0.0605
epoch [78/100], loss:0.0534
epoch [79/100], loss:0.0541
epoch [80/100], loss:0.0530
epoch [81/100], loss:0.0487
epoch [82/100], loss:0.0600
epoch [83/100], loss:0.0544
epoch [84/100], loss:0.0573
epoch [85/100], loss:0.0550
epoch [86/100], loss:0.0589
epoch [87/100], loss:0.0550
epoch [88/100], loss:0.0605
epoch [89/100], loss:0.0571
epoch [90/100], loss:0.0584
epoch [91/100], loss:0.0577
epoch [92/100], loss:0.0533
epoch [93/100], loss:0.0571
epoch [94/100], loss:0.0524
epoch [95/100], loss:0.0533
epoch [96/100], loss:0.0511
epoch [97/100], loss:0.0581
epoch [98/100], loss:0.0548
epoch [99/100], loss:0.0536
epoch [100/100], loss:0.0591
Running pruning iteration 8
************pruning 86.5782272 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 508 / 1152  0.4409722222222222
encoder.0.bias : 54 / 128  0.421875
encoder.2.weight : 120478 / 131072  0.9191741943359375
encoder.2.bias : 48 / 64  0.75
encoder.4.weight : 7120 / 8192  0.869140625
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 3494 / 4608  0.7582465277777778
encoder.6.bias : 10 / 16  0.625
encoder.9.weight : 885 / 1152  0.7682291666666666
encoder.9.bias : 4 / 8  0.5
decoder.0.weight : 7915 / 9216  0.8588324652777778
decoder.0.bias : 83 / 128  0.6484375
decoder.2.weight : 24379 / 32768  0.743988037109375
decoder.2.bias : 14 / 64  0.21875
decoder.4.weight : 4822 / 8192  0.588623046875
decoder.4.bias : 4 / 32  0.125
decoder.6.weight : 11643 / 12800  0.909609375
decoder.6.bias : 12 / 16  0.75
decoder.8.weight : 55 / 64  0.859375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 181559/209705 = 0.8657828854819866
Number of parameters in model 209705
epoch [1/100], loss:0.3791
epoch [2/100], loss:0.1623
epoch [3/100], loss:0.1351
epoch [4/100], loss:0.1291
epoch [5/100], loss:0.1111
epoch [6/100], loss:0.1148
epoch [7/100], loss:0.0992
epoch [8/100], loss:0.0916
epoch [9/100], loss:0.0983
epoch [10/100], loss:0.0815
epoch [11/100], loss:0.0897
epoch [12/100], loss:0.0851
epoch [13/100], loss:0.0866
epoch [14/100], loss:0.0906
epoch [15/100], loss:0.0814
epoch [16/100], loss:0.0839
epoch [17/100], loss:0.0739
epoch [18/100], loss:0.0788
epoch [19/100], loss:0.0819
epoch [20/100], loss:0.0829
epoch [21/100], loss:0.0842
epoch [22/100], loss:0.0819
epoch [23/100], loss:0.0800
epoch [24/100], loss:0.0758
epoch [25/100], loss:0.0820
epoch [26/100], loss:0.0797
epoch [27/100], loss:0.0788
epoch [28/100], loss:0.0740
epoch [29/100], loss:0.0693
epoch [30/100], loss:0.0680
epoch [31/100], loss:0.0792
epoch [32/100], loss:0.0708
epoch [33/100], loss:0.0675
epoch [34/100], loss:0.0688
epoch [35/100], loss:0.0732
epoch [36/100], loss:0.0699
epoch [37/100], loss:0.0742
epoch [38/100], loss:0.0711
epoch [39/100], loss:0.0731
epoch [40/100], loss:0.0675
epoch [41/100], loss:0.0679
epoch [42/100], loss:0.0680
epoch [43/100], loss:0.0708
epoch [44/100], loss:0.0663
epoch [45/100], loss:0.0684
epoch [46/100], loss:0.0723
epoch [47/100], loss:0.0598
epoch [48/100], loss:0.0710
epoch [49/100], loss:0.0706
epoch [50/100], loss:0.0728
epoch [51/100], loss:0.0739
epoch [52/100], loss:0.0685
epoch [53/100], loss:0.0727
epoch [54/100], loss:0.0656
epoch [55/100], loss:0.0727
epoch [56/100], loss:0.0704
epoch [57/100], loss:0.0692
epoch [58/100], loss:0.0683
epoch [59/100], loss:0.0703
epoch [60/100], loss:0.0710
epoch [61/100], loss:0.0697
epoch [62/100], loss:0.0670
epoch [63/100], loss:0.0611
epoch [64/100], loss:0.0715
epoch [65/100], loss:0.0636
epoch [66/100], loss:0.0724
epoch [67/100], loss:0.0679
epoch [68/100], loss:0.0672
epoch [69/100], loss:0.0749
epoch [70/100], loss:0.0646
epoch [71/100], loss:0.0707
epoch [72/100], loss:0.0635
epoch [73/100], loss:0.0587
epoch [74/100], loss:0.0631
epoch [75/100], loss:0.0727
epoch [76/100], loss:0.0616
epoch [77/100], loss:0.0691
epoch [78/100], loss:0.0650
epoch [79/100], loss:0.0644
epoch [80/100], loss:0.0657
epoch [81/100], loss:0.0618
epoch [82/100], loss:0.0661
epoch [83/100], loss:0.0598
epoch [84/100], loss:0.0607
epoch [85/100], loss:0.0729
epoch [86/100], loss:0.0593
epoch [87/100], loss:0.0611
epoch [88/100], loss:0.0621
epoch [89/100], loss:0.0609
epoch [90/100], loss:0.0692
epoch [91/100], loss:0.0683
epoch [92/100], loss:0.0725
epoch [93/100], loss:0.0625
epoch [94/100], loss:0.0670
epoch [95/100], loss:0.0634
epoch [96/100], loss:0.0639
epoch [97/100], loss:0.0666
epoch [98/100], loss:0.0614
epoch [99/100], loss:0.0607
epoch [100/100], loss:0.0632
Running pruning iteration 9
************pruning 89.26258176 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 553 / 1152  0.4800347222222222
encoder.0.bias : 61 / 128  0.4765625
encoder.2.weight : 122879 / 131072  0.9374923706054688
encoder.2.bias : 50 / 64  0.78125
encoder.4.weight : 7283 / 8192  0.8890380859375
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 3786 / 4608  0.8216145833333334
encoder.6.bias : 11 / 16  0.6875
encoder.9.weight : 941 / 1152  0.8168402777777778
encoder.9.bias : 5 / 8  0.625
decoder.0.weight : 8203 / 9216  0.8900824652777778
decoder.0.bias : 92 / 128  0.71875
decoder.2.weight : 25845 / 32768  0.788726806640625
decoder.2.bias : 17 / 64  0.265625
decoder.4.weight : 5181 / 8192  0.6324462890625
decoder.4.bias : 7 / 32  0.21875
decoder.6.weight : 12172 / 12800  0.9509375
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 58 / 64  0.90625
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 187188/209705 = 0.8926253546648864
Number of parameters in model 209705
epoch [1/100], loss:0.2178
epoch [2/100], loss:0.1752
epoch [3/100], loss:0.1700
epoch [4/100], loss:0.1569
epoch [5/100], loss:0.1446
epoch [6/100], loss:0.1472
epoch [7/100], loss:0.1292
epoch [8/100], loss:0.1386
epoch [9/100], loss:0.1393
epoch [10/100], loss:0.1269
epoch [11/100], loss:0.1189
epoch [12/100], loss:0.1233
epoch [13/100], loss:0.1198
epoch [14/100], loss:0.1150
epoch [15/100], loss:0.1175
epoch [16/100], loss:0.1034
epoch [17/100], loss:0.1134
epoch [18/100], loss:0.1052
epoch [19/100], loss:0.1137
epoch [20/100], loss:0.1116
epoch [21/100], loss:0.1039
epoch [22/100], loss:0.1083
epoch [23/100], loss:0.1075
epoch [24/100], loss:0.0955
epoch [25/100], loss:0.0935
epoch [26/100], loss:0.0923
epoch [27/100], loss:0.0857
epoch [28/100], loss:0.0878
epoch [29/100], loss:0.0915
epoch [30/100], loss:0.0863
epoch [31/100], loss:0.0939
epoch [32/100], loss:0.0992
epoch [33/100], loss:0.0877
epoch [34/100], loss:0.0936
epoch [35/100], loss:0.0824
epoch [36/100], loss:0.0891
epoch [37/100], loss:0.0899
epoch [38/100], loss:0.0816
epoch [39/100], loss:0.0882
epoch [40/100], loss:0.0973
epoch [41/100], loss:0.0831
epoch [42/100], loss:0.0927
epoch [43/100], loss:0.0838
epoch [44/100], loss:0.0908
epoch [45/100], loss:0.0824
epoch [46/100], loss:0.0889
epoch [47/100], loss:0.0795
epoch [48/100], loss:0.0829
epoch [49/100], loss:0.0798
epoch [50/100], loss:0.0847
epoch [51/100], loss:0.0829
epoch [52/100], loss:0.0849
epoch [53/100], loss:0.0801
epoch [54/100], loss:0.0887
epoch [55/100], loss:0.0815
epoch [56/100], loss:0.0883
epoch [57/100], loss:0.0810
epoch [58/100], loss:0.0840
epoch [59/100], loss:0.0783
epoch [60/100], loss:0.0805
epoch [61/100], loss:0.0713
epoch [62/100], loss:0.0813
epoch [63/100], loss:0.0902
epoch [64/100], loss:0.0794
epoch [65/100], loss:0.0889
epoch [66/100], loss:0.0858
epoch [67/100], loss:0.0766
epoch [68/100], loss:0.0821
epoch [69/100], loss:0.0761
epoch [70/100], loss:0.0793
epoch [71/100], loss:0.0729
epoch [72/100], loss:0.0800
epoch [73/100], loss:0.0774
epoch [74/100], loss:0.0879
epoch [75/100], loss:0.0737
epoch [76/100], loss:0.0834
epoch [77/100], loss:0.0716
epoch [78/100], loss:0.0774
epoch [79/100], loss:0.0818
epoch [80/100], loss:0.0809
epoch [81/100], loss:0.0755
epoch [82/100], loss:0.0766
epoch [83/100], loss:0.0733
epoch [84/100], loss:0.0724
epoch [85/100], loss:0.0738
epoch [86/100], loss:0.0770
epoch [87/100], loss:0.0736
epoch [88/100], loss:0.0833
epoch [89/100], loss:0.0706
epoch [90/100], loss:0.0707
epoch [91/100], loss:0.0780
epoch [92/100], loss:0.0791
epoch [93/100], loss:0.0709
epoch [94/100], loss:0.0811
epoch [95/100], loss:0.0806
epoch [96/100], loss:0.0716
epoch [97/100], loss:0.0728
epoch [98/100], loss:0.0745
epoch [99/100], loss:0.0731
epoch [100/100], loss:0.0688
Running pruning iteration 10
************pruning 91.41006540800001 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 564 / 1152  0.4895833333333333
encoder.0.bias : 63 / 128  0.4921875
encoder.2.weight : 123838 / 131072  0.9448089599609375
encoder.2.bias : 53 / 64  0.828125
encoder.4.weight : 7533 / 8192  0.9195556640625
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4209 / 4608  0.9134114583333334
encoder.6.bias : 14 / 16  0.875
encoder.9.weight : 998 / 1152  0.8663194444444444
encoder.9.bias : 5 / 8  0.625
decoder.0.weight : 8486 / 9216  0.9207899305555556
decoder.0.bias : 103 / 128  0.8046875
decoder.2.weight : 28080 / 32768  0.85693359375
decoder.2.bias : 17 / 64  0.265625
decoder.4.weight : 5439 / 8192  0.6639404296875
decoder.4.bias : 7 / 32  0.21875
decoder.6.weight : 12180 / 12800  0.9515625
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 58 / 64  0.90625
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 191691/209705 = 0.9140983762905033
Number of parameters in model 209705
epoch [1/100], loss:0.8774
epoch [2/100], loss:0.5056
epoch [3/100], loss:0.3919
epoch [4/100], loss:0.3579
epoch [5/100], loss:0.3262
epoch [6/100], loss:0.3334
epoch [7/100], loss:0.3567
epoch [8/100], loss:0.3532
epoch [9/100], loss:0.3402
epoch [10/100], loss:0.3412
epoch [11/100], loss:0.3421
epoch [12/100], loss:0.3135
epoch [13/100], loss:0.3260
epoch [14/100], loss:0.3262
epoch [15/100], loss:0.3578
epoch [16/100], loss:0.3249
epoch [17/100], loss:0.3204
epoch [18/100], loss:0.3477
epoch [19/100], loss:0.3272
epoch [20/100], loss:0.3256
epoch [21/100], loss:0.3282
epoch [22/100], loss:0.3277
epoch [23/100], loss:0.3457
epoch [24/100], loss:0.3202
epoch [25/100], loss:0.3234
epoch [26/100], loss:0.3448
epoch [27/100], loss:0.3387
epoch [28/100], loss:0.3158
epoch [29/100], loss:0.3165
epoch [30/100], loss:0.3280
epoch [31/100], loss:0.3397
epoch [32/100], loss:0.3270
epoch [33/100], loss:0.3309
epoch [34/100], loss:0.3285
epoch [35/100], loss:0.3303
epoch [36/100], loss:0.3418
epoch [37/100], loss:0.3238
epoch [38/100], loss:0.3343
epoch [39/100], loss:0.3235
epoch [40/100], loss:0.3404
epoch [41/100], loss:0.3189
epoch [42/100], loss:0.3447
epoch [43/100], loss:0.3298
epoch [44/100], loss:0.3205
epoch [45/100], loss:0.3386
epoch [46/100], loss:0.3191
epoch [47/100], loss:0.3332
epoch [48/100], loss:0.3434
epoch [49/100], loss:0.3381
epoch [50/100], loss:0.3461
epoch [51/100], loss:0.3243
epoch [52/100], loss:0.3225
epoch [53/100], loss:0.3437
epoch [54/100], loss:0.3234
epoch [55/100], loss:0.3385
epoch [56/100], loss:0.3396
epoch [57/100], loss:0.3411
epoch [58/100], loss:0.3356
epoch [59/100], loss:0.3216
epoch [60/100], loss:0.3332
epoch [61/100], loss:0.3491
epoch [62/100], loss:0.3086
epoch [63/100], loss:0.3351
epoch [64/100], loss:0.3221
epoch [65/100], loss:0.3127
epoch [66/100], loss:0.3208
epoch [67/100], loss:0.3173
epoch [68/100], loss:0.3245
epoch [69/100], loss:0.3527
epoch [70/100], loss:0.3311
epoch [71/100], loss:0.3297
epoch [72/100], loss:0.3522
epoch [73/100], loss:0.3096
epoch [74/100], loss:0.3203
epoch [75/100], loss:0.3502
epoch [76/100], loss:0.3251
epoch [77/100], loss:0.3512
epoch [78/100], loss:0.3561
epoch [79/100], loss:0.3345
epoch [80/100], loss:0.3124
epoch [81/100], loss:0.3229
epoch [82/100], loss:0.3308
epoch [83/100], loss:0.3214
epoch [84/100], loss:0.3344
epoch [85/100], loss:0.3189
epoch [86/100], loss:0.3320
epoch [87/100], loss:0.3452
epoch [88/100], loss:0.3351
epoch [89/100], loss:0.3432
epoch [90/100], loss:0.3223
epoch [91/100], loss:0.3268
epoch [92/100], loss:0.3116
epoch [93/100], loss:0.3293
epoch [94/100], loss:0.3271
epoch [95/100], loss:0.3168
epoch [96/100], loss:0.3245
epoch [97/100], loss:0.3301
epoch [98/100], loss:0.3319
epoch [99/100], loss:0.3397
epoch [100/100], loss:0.3374
Running pruning iteration 11
************pruning 93.12805232640001 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 723 / 1152  0.6276041666666666
encoder.0.bias : 78 / 128  0.609375
encoder.2.weight : 125178 / 131072  0.9550323486328125
encoder.2.bias : 54 / 64  0.84375
encoder.4.weight : 7672 / 8192  0.9365234375
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4289 / 4608  0.9307725694444444
encoder.6.bias : 14 / 16  0.875
encoder.9.weight : 1031 / 1152  0.8949652777777778
encoder.9.bias : 7 / 8  0.875
decoder.0.weight : 8626 / 9216  0.9359809027777778
decoder.0.bias : 110 / 128  0.859375
decoder.2.weight : 29158 / 32768  0.88983154296875
decoder.2.bias : 20 / 64  0.3125
decoder.4.weight : 5908 / 8192  0.72119140625
decoder.4.bias : 11 / 32  0.34375
decoder.6.weight : 12312 / 12800  0.961875
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 59 / 64  0.921875
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 195294/209705 = 0.9312796547531056
Number of parameters in model 209705
epoch [1/100], loss:0.5988
epoch [2/100], loss:0.4210
epoch [3/100], loss:0.3555
epoch [4/100], loss:0.3429
epoch [5/100], loss:0.3472
epoch [6/100], loss:0.3233
epoch [7/100], loss:0.3229
epoch [8/100], loss:0.3292
epoch [9/100], loss:0.3435
epoch [10/100], loss:0.3317
epoch [11/100], loss:0.3292
epoch [12/100], loss:0.3284
epoch [13/100], loss:0.3400
epoch [14/100], loss:0.3141
epoch [15/100], loss:0.3249
epoch [16/100], loss:0.3342
epoch [17/100], loss:0.3484
epoch [18/100], loss:0.3412
epoch [19/100], loss:0.3357
epoch [20/100], loss:0.3131
epoch [21/100], loss:0.3368
epoch [22/100], loss:0.3603
epoch [23/100], loss:0.3391
epoch [24/100], loss:0.3228
epoch [25/100], loss:0.3422
epoch [26/100], loss:0.3465
epoch [27/100], loss:0.3322
epoch [28/100], loss:0.3201
epoch [29/100], loss:0.3570
epoch [30/100], loss:0.3266
epoch [31/100], loss:0.3344
epoch [32/100], loss:0.3364
epoch [33/100], loss:0.3272
epoch [34/100], loss:0.3398
epoch [35/100], loss:0.3241
epoch [36/100], loss:0.3359
epoch [37/100], loss:0.3385
epoch [38/100], loss:0.3190
epoch [39/100], loss:0.3381
epoch [40/100], loss:0.3390
epoch [41/100], loss:0.3282
epoch [42/100], loss:0.3322
epoch [43/100], loss:0.3428
epoch [44/100], loss:0.3383
epoch [45/100], loss:0.3270
epoch [46/100], loss:0.3255
epoch [47/100], loss:0.3359
epoch [48/100], loss:0.3237
epoch [49/100], loss:0.3247
epoch [50/100], loss:0.3303
epoch [51/100], loss:0.3315
epoch [52/100], loss:0.3504
epoch [53/100], loss:0.3438
epoch [54/100], loss:0.3299
epoch [55/100], loss:0.3294
epoch [56/100], loss:0.3426
epoch [57/100], loss:0.3293
epoch [58/100], loss:0.3403
epoch [59/100], loss:0.3395
epoch [60/100], loss:0.3386
epoch [61/100], loss:0.3412
epoch [62/100], loss:0.3299
epoch [63/100], loss:0.3483
epoch [64/100], loss:0.3242
epoch [65/100], loss:0.3348
epoch [66/100], loss:0.3249
epoch [67/100], loss:0.3431
epoch [68/100], loss:0.3174
epoch [69/100], loss:0.3373
epoch [70/100], loss:0.3367
epoch [71/100], loss:0.3440
epoch [72/100], loss:0.3414
epoch [73/100], loss:0.3371
epoch [74/100], loss:0.3382
epoch [75/100], loss:0.3527
epoch [76/100], loss:0.3502
epoch [77/100], loss:0.3364
epoch [78/100], loss:0.3419
epoch [79/100], loss:0.3558
epoch [80/100], loss:0.3239
epoch [81/100], loss:0.3396
epoch [82/100], loss:0.3403
epoch [83/100], loss:0.3305
epoch [84/100], loss:0.3317
epoch [85/100], loss:0.3348
epoch [86/100], loss:0.3328
epoch [87/100], loss:0.3647
epoch [88/100], loss:0.3297
epoch [89/100], loss:0.3267
epoch [90/100], loss:0.3541
epoch [91/100], loss:0.3376
epoch [92/100], loss:0.3325
epoch [93/100], loss:0.3169
epoch [94/100], loss:0.3578
epoch [95/100], loss:0.3468
epoch [96/100], loss:0.3343
epoch [97/100], loss:0.3197
epoch [98/100], loss:0.3273
epoch [99/100], loss:0.3419
epoch [100/100], loss:0.3275
Running pruning iteration 12
************pruning 94.50244186112 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 823 / 1152  0.7144097222222222
encoder.0.bias : 92 / 128  0.71875
encoder.2.weight : 126241 / 131072  0.9631423950195312
encoder.2.bias : 57 / 64  0.890625
encoder.4.weight : 7792 / 8192  0.951171875
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4363 / 4608  0.9468315972222222
encoder.6.bias : 15 / 16  0.9375
encoder.9.weight : 1065 / 1152  0.9244791666666666
encoder.9.bias : 7 / 8  0.875
decoder.0.weight : 8751 / 9216  0.9495442708333334
decoder.0.bias : 112 / 128  0.875
decoder.2.weight : 29901 / 32768  0.912506103515625
decoder.2.bias : 28 / 64  0.4375
decoder.4.weight : 6399 / 8192  0.7811279296875
decoder.4.bias : 17 / 32  0.53125
decoder.6.weight : 12409 / 12800  0.969453125
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 60 / 64  0.9375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 198176/209705 = 0.9450227700817816
Number of parameters in model 209705
epoch [1/100], loss:0.5548
epoch [2/100], loss:0.3980
epoch [3/100], loss:0.3396
epoch [4/100], loss:0.3186
epoch [5/100], loss:0.2807
epoch [6/100], loss:0.2817
epoch [7/100], loss:0.2840
epoch [8/100], loss:0.2859
epoch [9/100], loss:0.2799
epoch [10/100], loss:0.2892
epoch [11/100], loss:0.2976
epoch [12/100], loss:0.2953
epoch [13/100], loss:0.2838
epoch [14/100], loss:0.2720
epoch [15/100], loss:0.2654
epoch [16/100], loss:0.2854
epoch [17/100], loss:0.2778
epoch [18/100], loss:0.2862
epoch [19/100], loss:0.2802
epoch [20/100], loss:0.2798
epoch [21/100], loss:0.2889
epoch [22/100], loss:0.2811
epoch [23/100], loss:0.2823
epoch [24/100], loss:0.2694
epoch [25/100], loss:0.2727
epoch [26/100], loss:0.2691
epoch [27/100], loss:0.2859
epoch [28/100], loss:0.2836
epoch [29/100], loss:0.2820
epoch [30/100], loss:0.2818
epoch [31/100], loss:0.2896
epoch [32/100], loss:0.2870
epoch [33/100], loss:0.2947
epoch [34/100], loss:0.2771
epoch [35/100], loss:0.2820
epoch [36/100], loss:0.2726
epoch [37/100], loss:0.2885
epoch [38/100], loss:0.2627
epoch [39/100], loss:0.2789
epoch [40/100], loss:0.2821
epoch [41/100], loss:0.2778
epoch [42/100], loss:0.2831
epoch [43/100], loss:0.2892
epoch [44/100], loss:0.2870
epoch [45/100], loss:0.2762
epoch [46/100], loss:0.2880
epoch [47/100], loss:0.2893
epoch [48/100], loss:0.2717
epoch [49/100], loss:0.2870
epoch [50/100], loss:0.2823
epoch [51/100], loss:0.2981
epoch [52/100], loss:0.2696
epoch [53/100], loss:0.2603
epoch [54/100], loss:0.2801
epoch [55/100], loss:0.2798
epoch [56/100], loss:0.2815
epoch [57/100], loss:0.2873
epoch [58/100], loss:0.2711
epoch [59/100], loss:0.2729
epoch [60/100], loss:0.2838
epoch [61/100], loss:0.2690
epoch [62/100], loss:0.2794
epoch [63/100], loss:0.2609
epoch [64/100], loss:0.2832
epoch [65/100], loss:0.2744
epoch [66/100], loss:0.2829
epoch [67/100], loss:0.2693
epoch [68/100], loss:0.2863
epoch [69/100], loss:0.2870
epoch [70/100], loss:0.2831
epoch [71/100], loss:0.2698
epoch [72/100], loss:0.2789
epoch [73/100], loss:0.2793
epoch [74/100], loss:0.2844
epoch [75/100], loss:0.2799
epoch [76/100], loss:0.2658
epoch [77/100], loss:0.2863
epoch [78/100], loss:0.2708
epoch [79/100], loss:0.2871
epoch [80/100], loss:0.2872
epoch [81/100], loss:0.2936
epoch [82/100], loss:0.2920
epoch [83/100], loss:0.2850
epoch [84/100], loss:0.2871
epoch [85/100], loss:0.2941
epoch [86/100], loss:0.2718
epoch [87/100], loss:0.2662
epoch [88/100], loss:0.2767
epoch [89/100], loss:0.2794
epoch [90/100], loss:0.2866
epoch [91/100], loss:0.2717
epoch [92/100], loss:0.2740
epoch [93/100], loss:0.2866
epoch [94/100], loss:0.2766
epoch [95/100], loss:0.2893
epoch [96/100], loss:0.2784
epoch [97/100], loss:0.2877
epoch [98/100], loss:0.2847
epoch [99/100], loss:0.2750
epoch [100/100], loss:0.2925
Running pruning iteration 13
************pruning 95.601953488896 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 931 / 1152  0.8081597222222222
encoder.0.bias : 104 / 128  0.8125
encoder.2.weight : 127483 / 131072  0.9726181030273438
encoder.2.bias : 58 / 64  0.90625
encoder.4.weight : 7910 / 8192  0.965576171875
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4429 / 4608  0.9611545138888888
encoder.6.bias : 15 / 16  0.9375
encoder.9.weight : 1094 / 1152  0.9496527777777778
encoder.9.bias : 7 / 8  0.875
decoder.0.weight : 8827 / 9216  0.9577907986111112
decoder.0.bias : 112 / 128  0.875
decoder.2.weight : 30364 / 32768  0.9266357421875
decoder.2.bias : 28 / 64  0.4375
decoder.4.weight : 6581 / 8192  0.8033447265625
decoder.4.bias : 17 / 32  0.53125
decoder.6.weight : 12418 / 12800  0.97015625
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 60 / 64  0.9375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 200482/209705 = 0.9560191697861281
Number of parameters in model 209705
epoch [1/100], loss:0.2825
epoch [2/100], loss:0.2725
epoch [3/100], loss:0.2678
epoch [4/100], loss:0.2774
epoch [5/100], loss:0.2568
epoch [6/100], loss:0.2583
epoch [7/100], loss:0.2731
epoch [8/100], loss:0.2772
epoch [9/100], loss:0.2666
epoch [10/100], loss:0.2711
epoch [11/100], loss:0.2618
epoch [12/100], loss:0.2635
epoch [13/100], loss:0.2552
epoch [14/100], loss:0.2643
epoch [15/100], loss:0.2679
epoch [16/100], loss:0.2639
epoch [17/100], loss:0.2612
epoch [18/100], loss:0.2772
epoch [19/100], loss:0.2674
epoch [20/100], loss:0.2623
epoch [21/100], loss:0.2650
epoch [22/100], loss:0.2681
epoch [23/100], loss:0.2413
epoch [24/100], loss:0.2585
epoch [25/100], loss:0.2660
epoch [26/100], loss:0.2613
epoch [27/100], loss:0.2670
epoch [28/100], loss:0.2664
epoch [29/100], loss:0.2535
epoch [30/100], loss:0.2563
epoch [31/100], loss:0.2456
epoch [32/100], loss:0.2724
epoch [33/100], loss:0.2612
epoch [34/100], loss:0.2544
epoch [35/100], loss:0.2715
epoch [36/100], loss:0.2636
epoch [37/100], loss:0.2589
epoch [38/100], loss:0.2671
epoch [39/100], loss:0.2652
epoch [40/100], loss:0.2585
epoch [41/100], loss:0.2687
epoch [42/100], loss:0.2530
epoch [43/100], loss:0.2520
epoch [44/100], loss:0.2608
epoch [45/100], loss:0.2569
epoch [46/100], loss:0.2566
epoch [47/100], loss:0.2694
epoch [48/100], loss:0.2586
epoch [49/100], loss:0.2726
epoch [50/100], loss:0.2522
epoch [51/100], loss:0.2525
epoch [52/100], loss:0.2496
epoch [53/100], loss:0.2524
epoch [54/100], loss:0.2677
epoch [55/100], loss:0.2592
epoch [56/100], loss:0.2551
epoch [57/100], loss:0.2535
epoch [58/100], loss:0.2549
epoch [59/100], loss:0.2486
epoch [60/100], loss:0.2601
epoch [61/100], loss:0.2542
epoch [62/100], loss:0.2637
epoch [63/100], loss:0.2548
epoch [64/100], loss:0.2531
epoch [65/100], loss:0.2608
epoch [66/100], loss:0.2664
epoch [67/100], loss:0.2562
epoch [68/100], loss:0.2513
epoch [69/100], loss:0.2587
epoch [70/100], loss:0.2575
epoch [71/100], loss:0.2646
epoch [72/100], loss:0.2758
epoch [73/100], loss:0.2551
epoch [74/100], loss:0.2400
epoch [75/100], loss:0.2552
epoch [76/100], loss:0.2553
epoch [77/100], loss:0.2514
epoch [78/100], loss:0.2558
epoch [79/100], loss:0.2473
epoch [80/100], loss:0.2550
epoch [81/100], loss:0.2580
epoch [82/100], loss:0.2549
epoch [83/100], loss:0.2702
epoch [84/100], loss:0.2593
epoch [85/100], loss:0.2501
epoch [86/100], loss:0.2560
epoch [87/100], loss:0.2615
epoch [88/100], loss:0.2540
epoch [89/100], loss:0.2440
epoch [90/100], loss:0.2500
epoch [91/100], loss:0.2471
epoch [92/100], loss:0.2454
epoch [93/100], loss:0.2563
epoch [94/100], loss:0.2580
epoch [95/100], loss:0.2632
epoch [96/100], loss:0.2588
epoch [97/100], loss:0.2590
epoch [98/100], loss:0.2611
epoch [99/100], loss:0.2740
epoch [100/100], loss:0.2467
Running pruning iteration 14
************pruning 96.4815627911168 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 958 / 1152  0.8315972222222222
encoder.0.bias : 107 / 128  0.8359375
encoder.2.weight : 128410 / 131072  0.9796905517578125
encoder.2.bias : 60 / 64  0.9375
encoder.4.weight : 7930 / 8192  0.968017578125
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4453 / 4608  0.9663628472222222
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1109 / 1152  0.9626736111111112
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 8909 / 9216  0.9666883680555556
decoder.0.bias : 122 / 128  0.953125
decoder.2.weight : 30971 / 32768  0.945159912109375
decoder.2.bias : 31 / 64  0.484375
decoder.4.weight : 6701 / 8192  0.8179931640625
decoder.4.bias : 17 / 32  0.53125
decoder.6.weight : 12420 / 12800  0.9703125
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 60 / 64  0.9375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 202326/209705 = 0.9648124746667939
Number of parameters in model 209705
epoch [1/100], loss:0.3455
epoch [2/100], loss:0.3141
epoch [3/100], loss:0.3310
epoch [4/100], loss:0.3119
epoch [5/100], loss:0.3450
epoch [6/100], loss:0.3259
epoch [7/100], loss:0.3282
epoch [8/100], loss:0.3153
epoch [9/100], loss:0.3491
epoch [10/100], loss:0.3252
epoch [11/100], loss:0.3304
epoch [12/100], loss:0.3350
epoch [13/100], loss:0.3276
epoch [14/100], loss:0.3284
epoch [15/100], loss:0.3419
epoch [16/100], loss:0.3396
epoch [17/100], loss:0.3180
epoch [18/100], loss:0.3220
epoch [19/100], loss:0.3186
epoch [20/100], loss:0.3069
epoch [21/100], loss:0.3163
epoch [22/100], loss:0.3088
epoch [23/100], loss:0.3130
epoch [24/100], loss:0.3113
epoch [25/100], loss:0.3314
epoch [26/100], loss:0.3330
epoch [27/100], loss:0.3235
epoch [28/100], loss:0.3209
epoch [29/100], loss:0.3138
epoch [30/100], loss:0.3589
epoch [31/100], loss:0.3233
epoch [32/100], loss:0.3241
epoch [33/100], loss:0.3359
epoch [34/100], loss:0.3169
epoch [35/100], loss:0.3473
epoch [36/100], loss:0.3200
epoch [37/100], loss:0.3309
epoch [38/100], loss:0.3226
epoch [39/100], loss:0.3313
epoch [40/100], loss:0.3231
epoch [41/100], loss:0.3259
epoch [42/100], loss:0.3141
epoch [43/100], loss:0.3133
epoch [44/100], loss:0.3349
epoch [45/100], loss:0.3110
epoch [46/100], loss:0.3130
epoch [47/100], loss:0.3388
epoch [48/100], loss:0.3130
epoch [49/100], loss:0.3096
epoch [50/100], loss:0.3274
epoch [51/100], loss:0.3162
epoch [52/100], loss:0.3269
epoch [53/100], loss:0.3264
epoch [54/100], loss:0.3051
epoch [55/100], loss:0.3107
epoch [56/100], loss:0.3094
epoch [57/100], loss:0.3292
epoch [58/100], loss:0.3311
epoch [59/100], loss:0.3191
epoch [60/100], loss:0.3228
epoch [61/100], loss:0.3343
epoch [62/100], loss:0.3295
epoch [63/100], loss:0.3215
epoch [64/100], loss:0.3230
epoch [65/100], loss:0.3248
epoch [66/100], loss:0.3101
epoch [67/100], loss:0.3366
epoch [68/100], loss:0.3092
epoch [69/100], loss:0.3279
epoch [70/100], loss:0.3194
epoch [71/100], loss:0.3519
epoch [72/100], loss:0.3123
epoch [73/100], loss:0.3297
epoch [74/100], loss:0.3293
epoch [75/100], loss:0.3160
epoch [76/100], loss:0.3179
epoch [77/100], loss:0.3314
epoch [78/100], loss:0.3130
epoch [79/100], loss:0.3130
epoch [80/100], loss:0.3263
epoch [81/100], loss:0.3248
epoch [82/100], loss:0.3166
epoch [83/100], loss:0.3487
epoch [84/100], loss:0.3263
epoch [85/100], loss:0.3267
epoch [86/100], loss:0.2983
epoch [87/100], loss:0.3123
epoch [88/100], loss:0.3048
epoch [89/100], loss:0.3449
epoch [90/100], loss:0.3135
epoch [91/100], loss:0.3190
epoch [92/100], loss:0.3325
epoch [93/100], loss:0.3559
epoch [94/100], loss:0.3349
epoch [95/100], loss:0.3202
epoch [96/100], loss:0.3092
epoch [97/100], loss:0.3156
epoch [98/100], loss:0.3249
epoch [99/100], loss:0.3225
epoch [100/100], loss:0.3058
Running pruning iteration 15
************pruning 97.18525023289344 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 1014 / 1152  0.8802083333333334
encoder.0.bias : 115 / 128  0.8984375
encoder.2.weight : 128983 / 131072  0.9840621948242188
encoder.2.bias : 61 / 64  0.953125
encoder.4.weight : 8001 / 8192  0.9766845703125
encoder.4.bias : 31 / 32  0.96875
encoder.6.weight : 4484 / 4608  0.9730902777777778
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1123 / 1152  0.9748263888888888
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 8970 / 9216  0.9733072916666666
decoder.0.bias : 122 / 128  0.953125
decoder.2.weight : 31366 / 32768  0.95721435546875
decoder.2.bias : 31 / 64  0.484375
decoder.4.weight : 6922 / 8192  0.844970703125
decoder.4.bias : 17 / 32  0.53125
decoder.6.weight : 12464 / 12800  0.97375
decoder.6.bias : 13 / 16  0.8125
decoder.8.weight : 61 / 64  0.953125
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 203802/209705 = 0.971850933454138
Number of parameters in model 209705
epoch [1/100], loss:0.4052
epoch [2/100], loss:0.3367
epoch [3/100], loss:0.3209
epoch [4/100], loss:0.3168
epoch [5/100], loss:0.3319
epoch [6/100], loss:0.3239
epoch [7/100], loss:0.3085
epoch [8/100], loss:0.3248
epoch [9/100], loss:0.3329
epoch [10/100], loss:0.3115
epoch [11/100], loss:0.3327
epoch [12/100], loss:0.3073
epoch [13/100], loss:0.3385
epoch [14/100], loss:0.3449
epoch [15/100], loss:0.3285
epoch [16/100], loss:0.3216
epoch [17/100], loss:0.3428
epoch [18/100], loss:0.3224
epoch [19/100], loss:0.3227
epoch [20/100], loss:0.3178
epoch [21/100], loss:0.3341
epoch [22/100], loss:0.3338
epoch [23/100], loss:0.3383
epoch [24/100], loss:0.3344
epoch [25/100], loss:0.3219
epoch [26/100], loss:0.3251
epoch [27/100], loss:0.3279
epoch [28/100], loss:0.3356
epoch [29/100], loss:0.3315
epoch [30/100], loss:0.3214
epoch [31/100], loss:0.3338
epoch [32/100], loss:0.3475
epoch [33/100], loss:0.3177
epoch [34/100], loss:0.3344
epoch [35/100], loss:0.3075
epoch [36/100], loss:0.3364
epoch [37/100], loss:0.3478
epoch [38/100], loss:0.3287
epoch [39/100], loss:0.3354
epoch [40/100], loss:0.3297
epoch [41/100], loss:0.3350
epoch [42/100], loss:0.3202
epoch [43/100], loss:0.3307
epoch [44/100], loss:0.3322
epoch [45/100], loss:0.3209
epoch [46/100], loss:0.3134
epoch [47/100], loss:0.3118
epoch [48/100], loss:0.3118
epoch [49/100], loss:0.3252
epoch [50/100], loss:0.3190
epoch [51/100], loss:0.3313
epoch [52/100], loss:0.3137
epoch [53/100], loss:0.3067
epoch [54/100], loss:0.3345
epoch [55/100], loss:0.3230
epoch [56/100], loss:0.3162
epoch [57/100], loss:0.3029
epoch [58/100], loss:0.3030
epoch [59/100], loss:0.3292
epoch [60/100], loss:0.2997
epoch [61/100], loss:0.3137
epoch [62/100], loss:0.3083
epoch [63/100], loss:0.3242
epoch [64/100], loss:0.3415
epoch [65/100], loss:0.3230
epoch [66/100], loss:0.3233
epoch [67/100], loss:0.3122
epoch [68/100], loss:0.3108
epoch [69/100], loss:0.3241
epoch [70/100], loss:0.3345
epoch [71/100], loss:0.3337
epoch [72/100], loss:0.3278
epoch [73/100], loss:0.3347
epoch [74/100], loss:0.3280
epoch [75/100], loss:0.3160
epoch [76/100], loss:0.3217
epoch [77/100], loss:0.3268
epoch [78/100], loss:0.3159
epoch [79/100], loss:0.3263
epoch [80/100], loss:0.3389
epoch [81/100], loss:0.3371
epoch [82/100], loss:0.3139
epoch [83/100], loss:0.3271
epoch [84/100], loss:0.3233
epoch [85/100], loss:0.3340
epoch [86/100], loss:0.3232
epoch [87/100], loss:0.3333
epoch [88/100], loss:0.3037
epoch [89/100], loss:0.3193
epoch [90/100], loss:0.3154
epoch [91/100], loss:0.3300
epoch [92/100], loss:0.3171
epoch [93/100], loss:0.3190
epoch [94/100], loss:0.3142
epoch [95/100], loss:0.3321
epoch [96/100], loss:0.3347
epoch [97/100], loss:0.3421
epoch [98/100], loss:0.3145
epoch [99/100], loss:0.3243
epoch [100/100], loss:0.3174
Running pruning iteration 16
************pruning 97.74820018631475 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 1049 / 1152  0.9105902777777778
encoder.0.bias : 116 / 128  0.90625
encoder.2.weight : 129422 / 131072  0.9874114990234375
encoder.2.bias : 61 / 64  0.953125
encoder.4.weight : 8051 / 8192  0.9827880859375
encoder.4.bias : 32 / 32  1.0
encoder.6.weight : 4513 / 4608  0.9793836805555556
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1130 / 1152  0.9809027777777778
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 9041 / 9216  0.9810112847222222
decoder.0.bias : 122 / 128  0.953125
decoder.2.weight : 31681 / 32768  0.966827392578125
decoder.2.bias : 31 / 64  0.484375
decoder.4.weight : 7103 / 8192  0.8670654296875
decoder.4.bias : 17 / 32  0.53125
decoder.6.weight : 12514 / 12800  0.97765625
decoder.6.bias : 14 / 16  0.875
decoder.8.weight : 61 / 64  0.953125
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 204982/209705 = 0.9774778856012016
Number of parameters in model 209705
epoch [1/100], loss:0.3390
epoch [2/100], loss:0.3210
epoch [3/100], loss:0.3381
epoch [4/100], loss:0.3535
epoch [5/100], loss:0.3445
epoch [6/100], loss:0.3440
epoch [7/100], loss:0.3269
epoch [8/100], loss:0.3292
epoch [9/100], loss:0.3191
epoch [10/100], loss:0.3227
epoch [11/100], loss:0.3384
epoch [12/100], loss:0.3178
epoch [13/100], loss:0.3356
epoch [14/100], loss:0.3237
epoch [15/100], loss:0.3058
epoch [16/100], loss:0.3376
epoch [17/100], loss:0.3291
epoch [18/100], loss:0.3290
epoch [19/100], loss:0.3221
epoch [20/100], loss:0.3263
epoch [21/100], loss:0.3382
epoch [22/100], loss:0.3520
epoch [23/100], loss:0.3243
epoch [24/100], loss:0.3604
epoch [25/100], loss:0.3198
epoch [26/100], loss:0.3071
epoch [27/100], loss:0.3482
epoch [28/100], loss:0.3389
epoch [29/100], loss:0.3407
epoch [30/100], loss:0.3212
epoch [31/100], loss:0.3488
epoch [32/100], loss:0.3351
epoch [33/100], loss:0.3378
epoch [34/100], loss:0.3353
epoch [35/100], loss:0.3326
epoch [36/100], loss:0.3411
epoch [37/100], loss:0.3369
epoch [38/100], loss:0.3195
epoch [39/100], loss:0.3166
epoch [40/100], loss:0.3201
epoch [41/100], loss:0.3259
epoch [42/100], loss:0.3414
epoch [43/100], loss:0.3333
epoch [44/100], loss:0.3261
epoch [45/100], loss:0.3275
epoch [46/100], loss:0.3402
epoch [47/100], loss:0.3446
epoch [48/100], loss:0.3312
epoch [49/100], loss:0.3373
epoch [50/100], loss:0.3370
epoch [51/100], loss:0.3312
epoch [52/100], loss:0.3235
epoch [53/100], loss:0.3529
epoch [54/100], loss:0.3437
epoch [55/100], loss:0.3141
epoch [56/100], loss:0.3197
epoch [57/100], loss:0.3451
epoch [58/100], loss:0.3444
epoch [59/100], loss:0.3623
epoch [60/100], loss:0.3472
epoch [61/100], loss:0.3533
epoch [62/100], loss:0.3569
epoch [63/100], loss:0.3020
epoch [64/100], loss:0.3243
epoch [65/100], loss:0.3363
epoch [66/100], loss:0.3450
epoch [67/100], loss:0.3248
epoch [68/100], loss:0.3260
epoch [69/100], loss:0.3246
epoch [70/100], loss:0.3276
epoch [71/100], loss:0.3313
epoch [72/100], loss:0.3506
epoch [73/100], loss:0.3136
epoch [74/100], loss:0.3503
epoch [75/100], loss:0.3519
epoch [76/100], loss:0.3328
epoch [77/100], loss:0.3418
epoch [78/100], loss:0.3127
epoch [79/100], loss:0.3476
epoch [80/100], loss:0.3459
epoch [81/100], loss:0.3520
epoch [82/100], loss:0.3250
epoch [83/100], loss:0.3380
epoch [84/100], loss:0.3150
epoch [85/100], loss:0.3224
epoch [86/100], loss:0.3326
epoch [87/100], loss:0.3255
epoch [88/100], loss:0.3288
epoch [89/100], loss:0.3276
epoch [90/100], loss:0.3169
epoch [91/100], loss:0.3521
epoch [92/100], loss:0.3368
epoch [93/100], loss:0.3445
epoch [94/100], loss:0.3449
epoch [95/100], loss:0.3198
epoch [96/100], loss:0.3328
epoch [97/100], loss:0.3484
epoch [98/100], loss:0.3455
epoch [99/100], loss:0.3300
epoch [100/100], loss:0.3256
Running pruning iteration 17
************pruning 98.1985601490518 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 1079 / 1152  0.9366319444444444
encoder.0.bias : 117 / 128  0.9140625
encoder.2.weight : 129702 / 131072  0.9895477294921875
encoder.2.bias : 62 / 64  0.96875
encoder.4.weight : 8072 / 8192  0.9853515625
encoder.4.bias : 32 / 32  1.0
encoder.6.weight : 4532 / 4608  0.9835069444444444
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1133 / 1152  0.9835069444444444
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 9072 / 9216  0.984375
decoder.0.bias : 122 / 128  0.953125
decoder.2.weight : 31902 / 32768  0.97357177734375
decoder.2.bias : 42 / 64  0.65625
decoder.4.weight : 7355 / 8192  0.8978271484375
decoder.4.bias : 20 / 32  0.625
decoder.6.weight : 12584 / 12800  0.983125
decoder.6.bias : 14 / 16  0.875
decoder.8.weight : 63 / 64  0.984375
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 205927/209705 = 0.9819842159223672
Number of parameters in model 209705
epoch [1/100], loss:0.6640
epoch [2/100], loss:0.4302
epoch [3/100], loss:0.3627
epoch [4/100], loss:0.3355
epoch [5/100], loss:0.3332
epoch [6/100], loss:0.3285
epoch [7/100], loss:0.3339
epoch [8/100], loss:0.3182
epoch [9/100], loss:0.3296
epoch [10/100], loss:0.3335
epoch [11/100], loss:0.3472
epoch [12/100], loss:0.3368
epoch [13/100], loss:0.3716
epoch [14/100], loss:0.3310
epoch [15/100], loss:0.3290
epoch [16/100], loss:0.3326
epoch [17/100], loss:0.3232
epoch [18/100], loss:0.3578
epoch [19/100], loss:0.3384
epoch [20/100], loss:0.3219
epoch [21/100], loss:0.3329
epoch [22/100], loss:0.3531
epoch [23/100], loss:0.3474
epoch [24/100], loss:0.3178
epoch [25/100], loss:0.3372
epoch [26/100], loss:0.3486
epoch [27/100], loss:0.3371
epoch [28/100], loss:0.3363
epoch [29/100], loss:0.3312
epoch [30/100], loss:0.3413
epoch [31/100], loss:0.3251
epoch [32/100], loss:0.3470
epoch [33/100], loss:0.3313
epoch [34/100], loss:0.3316
epoch [35/100], loss:0.3136
epoch [36/100], loss:0.3211
epoch [37/100], loss:0.3436
epoch [38/100], loss:0.3422
epoch [39/100], loss:0.3173
epoch [40/100], loss:0.3192
epoch [41/100], loss:0.3478
epoch [42/100], loss:0.3281
epoch [43/100], loss:0.3441
epoch [44/100], loss:0.3212
epoch [45/100], loss:0.3187
epoch [46/100], loss:0.3244
epoch [47/100], loss:0.3317
epoch [48/100], loss:0.3185
epoch [49/100], loss:0.3321
epoch [50/100], loss:0.3147
epoch [51/100], loss:0.3288
epoch [52/100], loss:0.3328
epoch [53/100], loss:0.3343
epoch [54/100], loss:0.3295
epoch [55/100], loss:0.3319
epoch [56/100], loss:0.3435
epoch [57/100], loss:0.3353
epoch [58/100], loss:0.3374
epoch [59/100], loss:0.3280
epoch [60/100], loss:0.3320
epoch [61/100], loss:0.3261
epoch [62/100], loss:0.3208
epoch [63/100], loss:0.3348
epoch [64/100], loss:0.3285
epoch [65/100], loss:0.3263
epoch [66/100], loss:0.3354
epoch [67/100], loss:0.3261
epoch [68/100], loss:0.3326
epoch [69/100], loss:0.3202
epoch [70/100], loss:0.3218
epoch [71/100], loss:0.3355
epoch [72/100], loss:0.3515
epoch [73/100], loss:0.3457
epoch [74/100], loss:0.3307
epoch [75/100], loss:0.3293
epoch [76/100], loss:0.3171
epoch [77/100], loss:0.3271
epoch [78/100], loss:0.3692
epoch [79/100], loss:0.3141
epoch [80/100], loss:0.3303
epoch [81/100], loss:0.3556
epoch [82/100], loss:0.3368
epoch [83/100], loss:0.3192
epoch [84/100], loss:0.3202
epoch [85/100], loss:0.3363
epoch [86/100], loss:0.3311
epoch [87/100], loss:0.3603
epoch [88/100], loss:0.3272
epoch [89/100], loss:0.3439
epoch [90/100], loss:0.3587
epoch [91/100], loss:0.3483
epoch [92/100], loss:0.3339
epoch [93/100], loss:0.3365
epoch [94/100], loss:0.3433
epoch [95/100], loss:0.3300
epoch [96/100], loss:0.3320
epoch [97/100], loss:0.3223
epoch [98/100], loss:0.3276
epoch [99/100], loss:0.3381
epoch [100/100], loss:0.3492
Running pruning iteration 18
************pruning 98.55884811924145 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 1096 / 1152  0.9513888888888888
encoder.0.bias : 120 / 128  0.9375
encoder.2.weight : 129930 / 131072  0.9912872314453125
encoder.2.bias : 64 / 64  1.0
encoder.4.weight : 8097 / 8192  0.9884033203125
encoder.4.bias : 32 / 32  1.0
encoder.6.weight : 4549 / 4608  0.9871961805555556
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1137 / 1152  0.9869791666666666
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 9101 / 9216  0.9875217013888888
decoder.0.bias : 125 / 128  0.9765625
decoder.2.weight : 32080 / 32768  0.97900390625
decoder.2.bias : 46 / 64  0.71875
decoder.4.weight : 7545 / 8192  0.9210205078125
decoder.4.bias : 22 / 32  0.6875
decoder.6.weight : 12636 / 12800  0.9871875
decoder.6.bias : 14 / 16  0.875
decoder.8.weight : 64 / 64  1.0
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 206682/209705 = 0.9855845115757851
Number of parameters in model 209705
epoch [1/100], loss:0.6147
epoch [2/100], loss:0.4203
epoch [3/100], loss:0.3613
epoch [4/100], loss:0.3462
epoch [5/100], loss:0.3512
epoch [6/100], loss:0.3372
epoch [7/100], loss:0.3348
epoch [8/100], loss:0.3420
epoch [9/100], loss:0.3442
epoch [10/100], loss:0.3467
epoch [11/100], loss:0.3225
epoch [12/100], loss:0.3388
epoch [13/100], loss:0.3425
epoch [14/100], loss:0.3222
epoch [15/100], loss:0.3438
epoch [16/100], loss:0.3380
epoch [17/100], loss:0.3293
epoch [18/100], loss:0.3274
epoch [19/100], loss:0.3327
epoch [20/100], loss:0.3449
epoch [21/100], loss:0.3307
epoch [22/100], loss:0.3178
epoch [23/100], loss:0.3253
epoch [24/100], loss:0.3393
epoch [25/100], loss:0.3153
epoch [26/100], loss:0.3334
epoch [27/100], loss:0.3256
epoch [28/100], loss:0.3127
epoch [29/100], loss:0.3250
epoch [30/100], loss:0.3430
epoch [31/100], loss:0.3341
epoch [32/100], loss:0.3237
epoch [33/100], loss:0.3460
epoch [34/100], loss:0.3282
epoch [35/100], loss:0.3560
epoch [36/100], loss:0.3364
epoch [37/100], loss:0.3233
epoch [38/100], loss:0.3224
epoch [39/100], loss:0.3310
epoch [40/100], loss:0.3254
epoch [41/100], loss:0.3279
epoch [42/100], loss:0.3440
epoch [43/100], loss:0.3204
epoch [44/100], loss:0.3243
epoch [45/100], loss:0.3366
epoch [46/100], loss:0.3484
epoch [47/100], loss:0.3369
epoch [48/100], loss:0.3278
epoch [49/100], loss:0.3191
epoch [50/100], loss:0.3375
epoch [51/100], loss:0.3302
epoch [52/100], loss:0.3313
epoch [53/100], loss:0.3153
epoch [54/100], loss:0.3241
epoch [55/100], loss:0.3373
epoch [56/100], loss:0.3356
epoch [57/100], loss:0.3045
epoch [58/100], loss:0.3162
epoch [59/100], loss:0.3448
epoch [60/100], loss:0.3371
epoch [61/100], loss:0.3292
epoch [62/100], loss:0.3309
epoch [63/100], loss:0.3355
epoch [64/100], loss:0.3404
epoch [65/100], loss:0.3487
epoch [66/100], loss:0.3344
epoch [67/100], loss:0.3175
epoch [68/100], loss:0.3325
epoch [69/100], loss:0.3306
epoch [70/100], loss:0.3143
epoch [71/100], loss:0.3498
epoch [72/100], loss:0.3398
epoch [73/100], loss:0.3311
epoch [74/100], loss:0.3474
epoch [75/100], loss:0.3241
epoch [76/100], loss:0.3518
epoch [77/100], loss:0.3198
epoch [78/100], loss:0.3640
epoch [79/100], loss:0.3461
epoch [80/100], loss:0.3321
epoch [81/100], loss:0.3232
epoch [82/100], loss:0.3226
epoch [83/100], loss:0.3286
epoch [84/100], loss:0.3146
epoch [85/100], loss:0.3283
epoch [86/100], loss:0.3386
epoch [87/100], loss:0.3356
epoch [88/100], loss:0.3394
epoch [89/100], loss:0.3404
epoch [90/100], loss:0.3323
epoch [91/100], loss:0.3174
epoch [92/100], loss:0.3382
epoch [93/100], loss:0.3403
epoch [94/100], loss:0.3087
epoch [95/100], loss:0.3326
epoch [96/100], loss:0.3455
epoch [97/100], loss:0.3176
epoch [98/100], loss:0.3309
epoch [99/100], loss:0.3439
epoch [100/100], loss:0.3390
Running pruning iteration 19
************pruning 98.84707849539316 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 1107 / 1152  0.9609375
encoder.0.bias : 121 / 128  0.9453125
encoder.2.weight : 130118 / 131072  0.9927215576171875
encoder.2.bias : 64 / 64  1.0
encoder.4.weight : 8119 / 8192  0.9910888671875
encoder.4.bias : 32 / 32  1.0
encoder.6.weight : 4564 / 4608  0.9904513888888888
encoder.6.bias : 16 / 16  1.0
encoder.9.weight : 1141 / 1152  0.9904513888888888
encoder.9.bias : 8 / 8  1.0
decoder.0.weight : 9119 / 9216  0.9894748263888888
decoder.0.bias : 127 / 128  0.9921875
decoder.2.weight : 32228 / 32768  0.9835205078125
decoder.2.bias : 47 / 64  0.734375
decoder.4.weight : 7703 / 8192  0.9403076171875
decoder.4.bias : 22 / 32  0.6875
decoder.6.weight : 12672 / 12800  0.99
decoder.6.bias : 15 / 16  0.9375
decoder.8.weight : 64 / 64  1.0
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 207287/209705 = 0.9884695167020338
Number of parameters in model 209705
epoch [1/100], loss:0.7162
epoch [2/100], loss:0.4471
epoch [3/100], loss:0.3609
epoch [4/100], loss:0.3462
epoch [5/100], loss:0.3375
epoch [6/100], loss:0.3137
epoch [7/100], loss:0.3564
epoch [8/100], loss:0.3336
epoch [9/100], loss:0.3289
epoch [10/100], loss:0.3377
epoch [11/100], loss:0.3382
epoch [12/100], loss:0.3159
epoch [13/100], loss:0.3221
epoch [14/100], loss:0.3354
epoch [15/100], loss:0.3270
epoch [16/100], loss:0.3332
epoch [17/100], loss:0.3413
epoch [18/100], loss:0.3404
epoch [19/100], loss:0.3377
epoch [20/100], loss:0.3274
epoch [21/100], loss:0.3352
epoch [22/100], loss:0.3434
epoch [23/100], loss:0.3504
epoch [24/100], loss:0.3309
epoch [25/100], loss:0.3476
epoch [26/100], loss:0.3406
epoch [27/100], loss:0.3319
epoch [28/100], loss:0.3507
epoch [29/100], loss:0.3505
epoch [30/100], loss:0.3501
epoch [31/100], loss:0.3280
epoch [32/100], loss:0.3167
epoch [33/100], loss:0.3598
epoch [34/100], loss:0.3568
epoch [35/100], loss:0.3251
epoch [36/100], loss:0.3308
epoch [37/100], loss:0.3269
epoch [38/100], loss:0.3418
epoch [39/100], loss:0.3204
epoch [40/100], loss:0.3246
epoch [41/100], loss:0.3407
epoch [42/100], loss:0.3235
epoch [43/100], loss:0.3360
epoch [44/100], loss:0.3424
epoch [45/100], loss:0.3230
epoch [46/100], loss:0.3420
epoch [47/100], loss:0.3407
epoch [48/100], loss:0.3235
epoch [49/100], loss:0.3164
epoch [50/100], loss:0.3368
epoch [51/100], loss:0.3304
epoch [52/100], loss:0.3335
epoch [53/100], loss:0.3225
epoch [54/100], loss:0.3554
epoch [55/100], loss:0.3262
epoch [56/100], loss:0.3434
epoch [57/100], loss:0.3584
epoch [58/100], loss:0.3227
epoch [59/100], loss:0.3580
epoch [60/100], loss:0.3354
epoch [61/100], loss:0.3363
epoch [62/100], loss:0.3211
epoch [63/100], loss:0.3252
epoch [64/100], loss:0.3203
epoch [65/100], loss:0.3378
epoch [66/100], loss:0.3236
epoch [67/100], loss:0.3313
epoch [68/100], loss:0.3198
epoch [69/100], loss:0.3316
epoch [70/100], loss:0.3476
epoch [71/100], loss:0.3359
epoch [72/100], loss:0.3297
epoch [73/100], loss:0.3251
epoch [74/100], loss:0.3315
epoch [75/100], loss:0.3263
epoch [76/100], loss:0.3251
epoch [77/100], loss:0.3420
epoch [78/100], loss:0.3288
epoch [79/100], loss:0.3334
epoch [80/100], loss:0.3126
epoch [81/100], loss:0.3253
epoch [82/100], loss:0.3292
epoch [83/100], loss:0.3240
epoch [84/100], loss:0.3567
epoch [85/100], loss:0.3365
epoch [86/100], loss:0.3191
epoch [87/100], loss:0.3328
epoch [88/100], loss:0.3385
epoch [89/100], loss:0.3437
epoch [90/100], loss:0.3391
epoch [91/100], loss:0.3356
epoch [92/100], loss:0.3187
epoch [93/100], loss:0.3591
epoch [94/100], loss:0.3275
epoch [95/100], loss:0.3353
epoch [96/100], loss:0.3470
epoch [97/100], loss:0.3335
epoch [98/100], loss:0.3231
epoch [99/100], loss:0.3343
epoch [100/100], loss:0.3562
Finished Iterative Pruning
