************pruning 95 of the network****************
Layer-wise pruning = False
Autoencoder layer-wise pruning percentages
encoder.0.weight : 2704 / 4608  0.5868055555555556
encoder.0.bias : 257 / 512  0.501953125
encoder.2.weight : 2055353 / 2097152  0.9800686836242676
encoder.2.bias : 226 / 256  0.8828125
encoder.4.weight : 128953 / 131072  0.9838333129882812
encoder.4.bias : 121 / 128  0.9453125
encoder.6.weight : 67535 / 73728  0.9160020616319444
encoder.6.bias : 41 / 64  0.640625
encoder.9.weight : 11846 / 18432  0.6426866319444444
encoder.9.bias : 8 / 32  0.25
decoder.0.weight : 117445 / 147456  0.7964748806423612
decoder.0.bias : 399 / 512  0.779296875
decoder.2.weight : 499288 / 524288  0.9523162841796875
decoder.2.bias : 205 / 256  0.80078125
decoder.4.weight : 121683 / 131072  0.9283676147460938
decoder.4.bias : 55 / 128  0.4296875
decoder.6.weight : 161842 / 204800  0.790244140625
decoder.6.bias : 21 / 64  0.328125
decoder.8.weight : 94 / 256  0.3671875
decoder.8.bias : 0 / 1  0.0
Fraction of weights pruned = 3168076/3334817 = 0.9499999550200205
Number of parameters in model 3334817
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,
        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,
        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,
        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,
        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,
        2, 0, 2, 7, 1, 8, 6, 4])
epoch [1/100], loss:0.0628
epoch [2/100], loss:0.0427
epoch [3/100], loss:0.0338
epoch [4/100], loss:0.0282
epoch [5/100], loss:0.0272
epoch [6/100], loss:0.0238
epoch [7/100], loss:0.0234
epoch [8/100], loss:0.0221
epoch [9/100], loss:0.0201
epoch [10/100], loss:0.0189
epoch [11/100], loss:0.0188
epoch [12/100], loss:0.0160
epoch [13/100], loss:0.0174
epoch [14/100], loss:0.0168
epoch [15/100], loss:0.0167
epoch [16/100], loss:0.0147
epoch [17/100], loss:0.0139
epoch [18/100], loss:0.0133
epoch [19/100], loss:0.0145
epoch [20/100], loss:0.0114
epoch [21/100], loss:0.0116
epoch [22/100], loss:0.0127
epoch [23/100], loss:0.0119
epoch [24/100], loss:0.0109
epoch [25/100], loss:0.0111
epoch [26/100], loss:0.0106
epoch [27/100], loss:0.0112
epoch [28/100], loss:0.0112
epoch [29/100], loss:0.0102
epoch [30/100], loss:0.0090
epoch [31/100], loss:0.0095
epoch [32/100], loss:0.0098
epoch [33/100], loss:0.0101
epoch [34/100], loss:0.0093
epoch [35/100], loss:0.0091
epoch [36/100], loss:0.0105
epoch [37/100], loss:0.0089
epoch [38/100], loss:0.0084
epoch [39/100], loss:0.0088
epoch [40/100], loss:0.0083
epoch [41/100], loss:0.0093
epoch [42/100], loss:0.0096
epoch [43/100], loss:0.0082
epoch [44/100], loss:0.0083
epoch [45/100], loss:0.0067
epoch [46/100], loss:0.0083
epoch [47/100], loss:0.0088
epoch [48/100], loss:0.0099
epoch [49/100], loss:0.0092
epoch [50/100], loss:0.0077
epoch [51/100], loss:0.0080
epoch [52/100], loss:0.0073
epoch [53/100], loss:0.0070
epoch [54/100], loss:0.0076
epoch [55/100], loss:0.0070
epoch [56/100], loss:0.0070
epoch [57/100], loss:0.0072
epoch [58/100], loss:0.0070
epoch [59/100], loss:0.0071
epoch [60/100], loss:0.0078
epoch [61/100], loss:0.0083
epoch [62/100], loss:0.0079
epoch [63/100], loss:0.0068
epoch [64/100], loss:0.0075
epoch [65/100], loss:0.0068
epoch [66/100], loss:0.0069
epoch [67/100], loss:0.0076
epoch [68/100], loss:0.0059
epoch [69/100], loss:0.0072
epoch [70/100], loss:0.0071
epoch [71/100], loss:0.0069
epoch [72/100], loss:0.0066
epoch [73/100], loss:0.0071
epoch [74/100], loss:0.0065
epoch [75/100], loss:0.0063
epoch [76/100], loss:0.0075
epoch [77/100], loss:0.0067
epoch [78/100], loss:0.0064
epoch [79/100], loss:0.0058
epoch [80/100], loss:0.0068
epoch [81/100], loss:0.0072
epoch [82/100], loss:0.0067
epoch [83/100], loss:0.0067
epoch [84/100], loss:0.0063
epoch [85/100], loss:0.0057
epoch [86/100], loss:0.0072
epoch [87/100], loss:0.0058
epoch [88/100], loss:0.0066
epoch [89/100], loss:0.0059
epoch [90/100], loss:0.0063
epoch [91/100], loss:0.0057
epoch [92/100], loss:0.0059
epoch [93/100], loss:0.0067
epoch [94/100], loss:0.0060
epoch [95/100], loss:0.0057
epoch [96/100], loss:0.0058
epoch [97/100], loss:0.0058
epoch [98/100], loss:0.0059
epoch [99/100], loss:0.0061
epoch [100/100], loss:0.0057
