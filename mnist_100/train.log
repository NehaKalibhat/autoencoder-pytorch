************pruning  100  of the netD****************
Layer-wise pruning =  False
Autoencoder layer-wise pruning percentages
encoder.0.weight :  144 / 144 1.0
encoder.0.bias :  16 / 16 1.0
encoder.3.weight :  1152 / 1152 1.0
encoder.3.bias :  8 / 8 1.0
decoder.0.weight :  1152 / 1152 1.0
decoder.0.bias :  16 / 16 1.0
decoder.2.weight :  3200 / 3200 1.0
decoder.2.bias :  8 / 8 1.0
decoder.4.weight :  32 / 32 1.0
decoder.4.bias :  1 / 1 1.0
Fraction of weights pruned = 5729/5729 = 1.0
Loading saved autoencoder named  ./mnist/before_train.pth
epoch [1/100], loss:0.9266
epoch [2/100], loss:0.9225
epoch [3/100], loss:0.9279
epoch [4/100], loss:0.9268
epoch [5/100], loss:0.9238
epoch [6/100], loss:0.9256
epoch [7/100], loss:0.9242
epoch [8/100], loss:0.9253
epoch [9/100], loss:0.9235
epoch [10/100], loss:0.9241
epoch [11/100], loss:0.9266
epoch [12/100], loss:0.9239
epoch [13/100], loss:0.9260
epoch [14/100], loss:0.9231
epoch [15/100], loss:0.9223
epoch [16/100], loss:0.9258
epoch [17/100], loss:0.9264
epoch [18/100], loss:0.9266
epoch [19/100], loss:0.9222
epoch [20/100], loss:0.9281
epoch [21/100], loss:0.9276
epoch [22/100], loss:0.9244
epoch [23/100], loss:0.9272
epoch [24/100], loss:0.9243
epoch [25/100], loss:0.9239
epoch [26/100], loss:0.9249
epoch [27/100], loss:0.9259
epoch [28/100], loss:0.9238
epoch [29/100], loss:0.9272
epoch [30/100], loss:0.9273
epoch [31/100], loss:0.9244
epoch [32/100], loss:0.9251
epoch [33/100], loss:0.9276
epoch [34/100], loss:0.9260
epoch [35/100], loss:0.9245
epoch [36/100], loss:0.9241
epoch [37/100], loss:0.9260
epoch [38/100], loss:0.9251
epoch [39/100], loss:0.9217
epoch [40/100], loss:0.9256
epoch [41/100], loss:0.9285
epoch [42/100], loss:0.9260
epoch [43/100], loss:0.9248
epoch [44/100], loss:0.9279
epoch [45/100], loss:0.9261
epoch [46/100], loss:0.9237
epoch [47/100], loss:0.9249
epoch [48/100], loss:0.9234
epoch [49/100], loss:0.9238
epoch [50/100], loss:0.9273
epoch [51/100], loss:0.9254
epoch [52/100], loss:0.9254
epoch [53/100], loss:0.9259
epoch [54/100], loss:0.9225
epoch [55/100], loss:0.9224
epoch [56/100], loss:0.9253
epoch [57/100], loss:0.9284
epoch [58/100], loss:0.9251
epoch [59/100], loss:0.9262
epoch [60/100], loss:0.9247
epoch [61/100], loss:0.9255
epoch [62/100], loss:0.9240
epoch [63/100], loss:0.9209
epoch [64/100], loss:0.9246
epoch [65/100], loss:0.9249
epoch [66/100], loss:0.9243
epoch [67/100], loss:0.9218
epoch [68/100], loss:0.9284
epoch [69/100], loss:0.9254
epoch [70/100], loss:0.9242
epoch [71/100], loss:0.9261
epoch [72/100], loss:0.9272
epoch [73/100], loss:0.9265
epoch [74/100], loss:0.9232
epoch [75/100], loss:0.9250
epoch [76/100], loss:0.9250
epoch [77/100], loss:0.9262
epoch [78/100], loss:0.9274
epoch [79/100], loss:0.9234
epoch [80/100], loss:0.9277
epoch [81/100], loss:0.9215
epoch [82/100], loss:0.9243
epoch [83/100], loss:0.9257
epoch [84/100], loss:0.9270
epoch [85/100], loss:0.9251
epoch [86/100], loss:0.9266
epoch [87/100], loss:0.9262
epoch [88/100], loss:0.9269
epoch [89/100], loss:0.9275
epoch [90/100], loss:0.9235
epoch [91/100], loss:0.9261
epoch [92/100], loss:0.9247
epoch [93/100], loss:0.9258
epoch [94/100], loss:0.9273
epoch [95/100], loss:0.9249
epoch [96/100], loss:0.9248
epoch [97/100], loss:0.9262
epoch [98/100], loss:0.9244
epoch [99/100], loss:0.9247
epoch [100/100], loss:0.9261
